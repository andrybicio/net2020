{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pygraphviz as pgv\n",
    "import pydot\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diro</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>-0.467500</td>\n",
       "      <td>0.307777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gente</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.484476</td>\n",
       "      <td>0.475986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guerra</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>-0.409666</td>\n",
       "      <td>0.139754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>portato</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.43750</td>\n",
       "      <td>-0.645658</td>\n",
       "      <td>0.455007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>casa</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>-0.547190</td>\n",
       "      <td>0.186682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40014</th>\n",
       "      <td>#rip</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40015</th>\n",
       "      <td>#aspettandoprometeo</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40016</th>\n",
       "      <td>#ivreich</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40017</th>\n",
       "      <td>satanasso</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40018</th>\n",
       "      <td>consigliatissima</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40019 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lemma  positive_score  negative_score  polarity  \\\n",
       "0                     diro          0.1250         0.28125 -0.467500   \n",
       "1                    gente          0.4375         0.18750  0.484476   \n",
       "2                   guerra          0.0625         0.12500 -0.409666   \n",
       "3                  portato          0.1250         0.43750 -0.645658   \n",
       "4                     casa          0.0650         0.17500 -0.547190   \n",
       "...                    ...             ...             ...       ...   \n",
       "40014                 #rip          0.0000         0.00000  0.000000   \n",
       "40015  #aspettandoprometeo          0.0000         0.00000  0.000000   \n",
       "40016             #ivreich          0.0000         0.00000  0.000000   \n",
       "40017            satanasso          0.0000         0.50000 -1.000000   \n",
       "40018     consigliatissima          0.0000         0.00000  0.000000   \n",
       "\n",
       "       intensity  \n",
       "0       0.307777  \n",
       "1       0.475986  \n",
       "2       0.139754  \n",
       "3       0.455007  \n",
       "4       0.186682  \n",
       "...          ...  \n",
       "40014   0.000000  \n",
       "40015   0.000000  \n",
       "40016   0.000000  \n",
       "40017   0.500000  \n",
       "40018   0.000000  \n",
       "\n",
       "[40019 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words = pd.read_csv('lemmas_sentiment_correct.csv', index_col = 0)\n",
    "words = pd.read_csv('lemmas_sentiment_correct.csv')\n",
    "words = words.dropna().reset_index(drop = True)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Sentiment dictionary\n",
    "\n",
    "See here for better comprehension of the sentiment dictionary\n",
    "\n",
    "http://valeriobasile.github.io/twita/sentix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Wordnet synset ID</th>\n",
       "      <th>positive score</th>\n",
       "      <th>negative score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abile</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intelligente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valente</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capace</td>\n",
       "      <td>a</td>\n",
       "      <td>1740</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>incapace</td>\n",
       "      <td>a</td>\n",
       "      <td>2098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74604</th>\n",
       "      <td>imbronciarsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74605</th>\n",
       "      <td>rannuvolarsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74606</th>\n",
       "      <td>rasserenarsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771169</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74607</th>\n",
       "      <td>rischiararsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771169</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74608</th>\n",
       "      <td>schiarirsi</td>\n",
       "      <td>v</td>\n",
       "      <td>2771169</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74606 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lemma POS  Wordnet synset ID  positive score  negative score  \\\n",
       "0             abile   a               1740           0.125            0.00   \n",
       "1      intelligente   a               1740           0.125            0.00   \n",
       "2           valente   a               1740           0.125            0.00   \n",
       "3            capace   a               1740           0.125            0.00   \n",
       "4          incapace   a               2098           0.000            0.75   \n",
       "...             ...  ..                ...             ...             ...   \n",
       "74604  imbronciarsi   v            2771020           0.000            0.25   \n",
       "74605  rannuvolarsi   v            2771020           0.000            0.25   \n",
       "74606  rasserenarsi   v            2771169           0.125            0.00   \n",
       "74607  rischiararsi   v            2771169           0.125            0.00   \n",
       "74608    schiarirsi   v            2771169           0.125            0.00   \n",
       "\n",
       "       polarity  intensity  \n",
       "0           1.0      0.125  \n",
       "1           1.0      0.125  \n",
       "2           1.0      0.125  \n",
       "3           1.0      0.125  \n",
       "4          -1.0      0.750  \n",
       "...         ...        ...  \n",
       "74604      -1.0      0.250  \n",
       "74605      -1.0      0.250  \n",
       "74606       1.0      0.125  \n",
       "74607       1.0      0.125  \n",
       "74608       1.0      0.125  \n",
       "\n",
       "[74606 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentix = pd.read_csv('sentix/sentix', sep = \"\\t\", header = None, dtype = {'lemmas': object})\n",
    "sentix.columns = ['lemma', 'POS', 'Wordnet synset ID' ,'positive score', 'negative score', 'polarity','intensity']\n",
    "sentix = sentix.dropna()\n",
    "sentix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(pos, neg):\n",
    "    \n",
    "    if (pos == 0.)and(neg == 0.):\n",
    "        return 0.\n",
    "    \n",
    "    elif pos != 0.:\n",
    "        theta = np.arctan(neg/pos)\n",
    "    \n",
    "    elif pos == 0: \n",
    "        theta = np.arctan(np.Inf)\n",
    "    \n",
    "    return 1.-4.*theta/np.pi\n",
    "\n",
    "def get_exact_match(word, sentix):\n",
    "    subset = sentix[sentix.loc[:,'lemma'].str.fullmatch(word) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean,neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "def get_match(word, sentix):\n",
    "    subset = sentix[sentix.loc[:,'lemma'].str.match(word) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean,neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "def get_contains(word, sentix):\n",
    "    subset = sentix[sentix.loc[:,'lemma'].str.contains(word) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean,neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "def get_similar(word, sentix):\n",
    "    similar_words = difflib.get_close_matches(word, sentix.lemma, n = 8, cutoff = 0.8)\n",
    "    subset = sentix[sentix.loc[:,'lemma'].isin(similar_words) == True]\n",
    "    \n",
    "    if (len(subset) == 0):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "    \n",
    "    if (len(subset) == 1):\n",
    "        return subset.loc[:,['lemma','positive score','negative score','polarity','intensity']]\n",
    "        \n",
    "    elif (len(subset) > 1):\n",
    "        pos_mean  = subset.loc[:,'positive score'].mean()\n",
    "        neg_mean  = subset.loc[:,'negative score'].mean()\n",
    "        polarity  = get_polarity(pos_mean ,neg_mean)\n",
    "        intensity = np.sqrt(pos_mean**2 + neg_mean**2)\n",
    "        \n",
    "        dictionary = {'lemma': [word], 'positive score' : [pos_mean],'negative score' : [neg_mean],\n",
    "                             'polarity' : [polarity],'intensity' : [intensity]}\n",
    "        \n",
    "        return pd.DataFrame.from_dict(dictionary)\n",
    "\n",
    "#instead of returning a row of a dictionary, return a list of its values\n",
    "def denest_row(row):\n",
    "    \n",
    "    return [row.loc[:,'lemma'].values[0], \n",
    "            row.loc[:,'positive score'].values[0], \n",
    "            row.loc[:,'negative score'].values[0], \n",
    "            row.loc[:,'polarity'].values[0],\n",
    "            row.loc[:,'intensity'].values[0]]\n",
    "\n",
    "def get_rows_data(word, sentix, use_similarity = False):\n",
    "    \n",
    "    row = get_exact_match(word, sentix)\n",
    "    \n",
    "    #if there are no exact matches, try others\n",
    "    if (len(row) == 0):\n",
    "        print('no exact match')\n",
    "        row = get_match(word, sentix)\n",
    "        \n",
    "        #if there are no matches, try the others\n",
    "        if (len(row) == 0):\n",
    "            print('no match')\n",
    "            row = get_contains(word, sentix)\n",
    "            \n",
    "            #if word is not even contained and we want similarities then try it\n",
    "            if ((len(row) == 0) and (use_similarity)):\n",
    "                print('no contains')\n",
    "                row = get_similar(word, sentix)\n",
    "            \n",
    "                #if still no matches, give up and return an empty dataframe\n",
    "                if (len(row) == 0):\n",
    "                    print('no similar')\n",
    "                    dictionary = {'lemma': [word], 'positive score' : [0.],'negative score' : [0.],\n",
    "                                  'polarity' : [0.],'intensity' : [0.]}\n",
    "                    row =  pd.DataFrame.from_dict(dictionary)\n",
    "            \n",
    "            #if we do not want similarities then return the empty dataframe        \n",
    "            elif (len(row) == 0):\n",
    "                print('no contains')\n",
    "                dictionary = {'lemma': [word], 'positive score' : [0.],'negative score' : [0.],\n",
    "                                  'polarity' : [0.],'intensity' : [0.]}\n",
    "                row = pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "    row = row.reset_index(drop = True)\n",
    "    #get back the original word    \n",
    "    row.lemma = word\n",
    "    \n",
    "    #compute the right polarity\n",
    "    if (row.loc[0,'positive score'] != 0.):\n",
    "        row.polarity = get_polarity(row.loc[0,'positive score'] , row.loc[0,'negative score'] )\n",
    "        \n",
    "\n",
    "\n",
    "    #denest it\n",
    "    return denest_row(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next call to the function get_rows_data(word, sentix, use_similarity = False) above does the following:\n",
    "\n",
    "+ **Output**: Returns a row of the kind (lemma, positive score, negative score, polarity, intensity)\n",
    "\n",
    "### **What it does**: it looks for a matching word in the sentix dataframe. \n",
    "* If there is one *exactly* matching, returns that row\n",
    "* if there are many, then compute the mean between the two positive and negative scores among the different rows, polarity is the sign of the difference (positive_score - negative_score) and intensity is the $L_2$ norm (i.e. sqrt(pos^2 + neg^2))\n",
    "* If there is **NONE** exactly matching, then look for any string that *matches* a word in the sentix dictionary. Same reasoning as before. If there is only one matching then returns that row, otherwise do some algebra.\n",
    "\n",
    "* If still there are none matching, then look for any string that *contains* (indeed to *contain* is a less strict relation that *matching* that in turn is a less strict relation than *exactly match*)\n",
    "\n",
    "* If still there are none contained, if a flag is set to true, then take the most similar words in the lemmas list and use them to create sentiment. \n",
    "\n",
    "* If even this way there are none, or the previous flag was set to false, return a row of the kind      (word, 0.  ,  0.  , 0.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['lemma', 'positive_score', 'negative_score', 'polarity', 'intensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word # 1 / 40019\n",
      "diro\n",
      "no exact match\n",
      "gente\n",
      "no exact match\n",
      "guerra\n",
      "portato\n",
      "no exact match\n",
      "casa\n",
      "no exact match\n",
      "rimpatriare\n",
      "no exact match\n",
      "no match\n",
      "no contains\n",
      "marcello\n",
      "no exact match\n",
      "no match\n",
      "no contains\n",
      "perfavore\n",
      "no exact match\n",
      "no match\n",
      "no contains\n",
      "patrio\n",
      "no exact match\n",
      "patriota\n",
      "no exact match\n",
      "difeso\n",
      "no exact match\n",
      "no match\n",
      "no contains\n",
      "proprio\n",
      "radice\n",
      "no exact match\n",
      "soccombere\n",
      "roma\n",
      "no exact match\n",
      "islamico\n",
      "no exact match\n",
      "no match\n",
      "accoltellare\n",
      "no exact match\n",
      "no match\n",
      "no contains\n",
      "uomo\n",
      "crocifisso\n",
      "no exact match\n",
      "no match\n",
      "no contains\n",
      "no similar\n",
      "collare\n",
      "accadere\n",
      "stazione\n",
      "no exact match\n",
      "termine\n",
      "no exact match\n",
      "aggressore\n",
      "no exact match\n",
      "no match\n",
      "no contains\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-c2ff7e189f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msentiment_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_rows_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-f7ac100bdb7b>\u001b[0m in \u001b[0;36mget_rows_data\u001b[0;34m(word, sentix, use_similarity)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muse_similarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no contains'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m#if still no matches, give up and return an empty dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-f7ac100bdb7b>\u001b[0m in \u001b[0;36mget_similar\u001b[0;34m(word, sentix)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0msimilar_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdifflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_close_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lemma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/difflib.py\u001b[0m in \u001b[0;36mget_close_matches\u001b[0;34m(word, possibilities, n, cutoff)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seq2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibilities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seq1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_quick_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcutoff\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m            \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquick_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcutoff\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/difflib.py\u001b[0m in \u001b[0;36mset_seq1\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatching_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentiment_list = [] \n",
    "# for word in words.iloc[0:100,0]:\n",
    "for i, word in enumerate (words.iloc[:,0]):\n",
    "    if ( i % 50 == 0): print(\"word #\", i+1, \"/\", len(words))\n",
    "    print(word)    \n",
    "    sentiment_list.append(get_rows_data(word, sentix, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diro</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.307777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gente</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.475986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guerra</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.139754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>portato</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.43750</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.455007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>casa</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.186682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40014</th>\n",
       "      <td>#rip</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40015</th>\n",
       "      <td>#aspettandoprometeo</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40016</th>\n",
       "      <td>#ivreich</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40017</th>\n",
       "      <td>satanasso</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40018</th>\n",
       "      <td>consigliatissima</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40019 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lemma  positive_score  negative_score  polarity  \\\n",
       "0                     diro          0.1250         0.28125      -1.0   \n",
       "1                    gente          0.4375         0.18750       1.0   \n",
       "2                   guerra          0.0625         0.12500      -1.0   \n",
       "3                  portato          0.1250         0.43750      -1.0   \n",
       "4                     casa          0.0650         0.17500      -1.0   \n",
       "...                    ...             ...             ...       ...   \n",
       "40014                 #rip          0.0000         0.00000       0.0   \n",
       "40015  #aspettandoprometeo          0.0000         0.00000       0.0   \n",
       "40016             #ivreich          0.0000         0.00000       0.0   \n",
       "40017            satanasso          0.0000         0.50000      -1.0   \n",
       "40018     consigliatissima          0.0000         0.00000       0.0   \n",
       "\n",
       "       intensity  \n",
       "0       0.307777  \n",
       "1       0.475986  \n",
       "2       0.139754  \n",
       "3       0.455007  \n",
       "4       0.186682  \n",
       "...          ...  \n",
       "40014   0.000000  \n",
       "40015   0.000000  \n",
       "40016   0.000000  \n",
       "40017   0.500000  \n",
       "40018   0.000000  \n",
       "\n",
       "[40019 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dataframe = pd.DataFrame.from_records(sentiment_list, columns = labels)\n",
    "sentiment_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dataframe.to_csv('lemmas_sentiment.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
