{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Network_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZtII1Dfo4r9",
        "outputId": "e6ec638c-307e-4b82-a699-7c706d4f9da1"
      },
      "source": [
        "pip install networkx"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (2.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KipyGXCFobCW"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import networkx as nx\r\n",
        "from operator import itemgetter"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcFUx97co-bt"
      },
      "source": [
        "**Importing nodes and edges lists**\r\n",
        "  \r\n",
        "  Here we are using the full graph \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn71V4tZoeSl"
      },
      "source": [
        "nodes_df = pd.read_csv('words_with_ratings5.csv', low_memory=False)\r\n",
        "edges_df = pd.read_csv('Lemmas_Edgeslist.csv', low_memory=False)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUjeOL-tpQsT"
      },
      "source": [
        "**Creating NetworkX Graph object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNxasnAUHEcv"
      },
      "source": [
        "#Creating a NetworkX Graph\r\n",
        "G = nx.Graph()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOjZ6z94BxJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a03c9f-19ac-4fd8-b4ef-ecb5cd04b4f2"
      },
      "source": [
        "G = nx.from_pandas_edgelist(edges_df, 'source', 'target', ['weight'])\t\r\n",
        "\r\n",
        "nodes = pd.read_csv('words_with_ratings5.csv')\r\n",
        "data = nodes.set_index('word').to_dict('index').items()\r\n",
        "\r\n",
        "G.add_nodes_from(data)\r\n",
        "print(G.nodes(data=True))\r\n",
        "print(G.edges(data=True))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joM8nR63r5IR"
      },
      "source": [
        "Printing some Graph information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84vgSBI4y4QY",
        "outputId": "4f7f7a49-4e94-4d5f-d174-a20491827a08"
      },
      "source": [
        "#Checking if the edges and nodes were added successfully\r\n",
        "print(nx.info(G)) # Print information about the Graph"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: \n",
            "Type: Graph\n",
            "Number of nodes: 39364\n",
            "Number of edges: 2827611\n",
            "Average degree: 143.6648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qw8pRe4ptUc"
      },
      "source": [
        "###Some Network Statistics below can be done using Gephi while others are more flexible to try in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_-MINZlwpTI"
      },
      "source": [
        "####**PART ONE:** Metrics Related to the network structure (Density, Transitivity)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpLLFtQvw-IR"
      },
      "source": [
        "**DENSITY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOBEkbBaNbpY",
        "outputId": "679d6e2a-800b-4661-d13e-cdbf742f947d"
      },
      "source": [
        "#Overall Density of the network\r\n",
        "density = nx.density(G)\r\n",
        "print(\"Network density:\", density)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network density: 0.0036497426681987677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOZUIARStalt"
      },
      "source": [
        "This **Density** value just means that our network is weakly connected, this is predictable since we are dealing with a huge network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXijSxeYxCWx"
      },
      "source": [
        "**TRANSITIVITY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1E6kpAJxOVy"
      },
      "source": [
        "#Overall Density of the network\r\n",
        "transitivity = nx.transitivity(G)\r\n",
        "print(\"Network transitivity:\", transitivity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPw8XvIXxkLP"
      },
      "source": [
        "**Transitivity** is just a way to measure triadic closure, teh value we get tells us how the nodes are interconnected. This suggest that we should look more into the importance of each node(degrees, centrality, page rank etc..) using the metrics in PART 2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmBYAVVDySaB"
      },
      "source": [
        "####**PART TWO:** Metrics Related to the importance of each node\r\n",
        "In this section we add new attributes to each node depending on its centrality, degree..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96TtZq1_typY"
      },
      "source": [
        "**DEGREES** : Create **degrees dictionary**, mapping each word to their respective degrees. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyNvjlFGPFnf"
      },
      "source": [
        "degree_dict = dict(G.degree(G.nodes()))\r\n",
        "nx.set_node_attributes(G, degree_dict, 'degree')\r\n",
        "#It is important to set degree as an attribute of node alongside the other attributes "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2-ZlJ5rPWIG"
      },
      "source": [
        "#Sorting in desceding order (this will be important if we want to use nodes removal)\r\n",
        "sorted_degree = sorted(degree_dict.items(), key=itemgetter(1), reverse=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViX8L1MYPZEj",
        "outputId": "93c973ef-6006-4024-bbf4-098227c08a66"
      },
      "source": [
        "print(\"Top 20 nodes by degree:\")\r\n",
        "for d in sorted_degree[:20]:\r\n",
        "    print(d)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 20 nodes by degree:\n",
            "('fare', 10428)\n",
            "('anno', 10109)\n",
            "('politico', 9649)\n",
            "('partire', 9622)\n",
            "('italia', 9614)\n",
            "('sempre', 9538)\n",
            "('italiano', 9406)\n",
            "('quando', 8998)\n",
            "('potere', 8830)\n",
            "('parlare', 8672)\n",
            "('dire', 8096)\n",
            "('lavorare', 8077)\n",
            "('salvini', 8039)\n",
            "('governare', 7989)\n",
            "('persona', 7841)\n",
            "('bene', 7483)\n",
            "('votare', 7481)\n",
            "('andare', 7253)\n",
            "('paese', 7236)\n",
            "('mettere', 7224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWYgj4gKy5tJ"
      },
      "source": [
        "We see what hubs we have: 'fare' ; 'anno' ; 'politico'..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au_1kKt7uhVs"
      },
      "source": [
        "**Betweeness Centrality Dictionary**\r\n",
        "\r\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1FIgpOEyimW"
      },
      "source": [
        "It is quite informative to see what is the most central node in the network. This measure is more relevant because it doesnâ€™t care about the number of edges any one node or set of nodes has. Betweenness centrality looks at all the shortest paths that pass through a particular node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyKMjXd9zzh8"
      },
      "source": [
        "TAKES LOTS OF TIME TO RUN, calculating every possible shortest path in the network is exhaustive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsTKdn8fPf_H"
      },
      "source": [
        "#Inspecting the centrality of each node --> important if we want to implement nodes removal\r\n",
        "betweenness_dict = nx.betweenness_centrality(G) # Run betweenness centrality\r\n",
        "nx.set_node_attributes(G, betweenness_dict, 'betweenness')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxGlRouQPmFI"
      },
      "source": [
        "sorted_betweenness = sorted(betweenness_dict.items(), key=itemgetter(1), reverse=True)\r\n",
        "print(\"Top 20 nodes by betweenness centrality:\")\r\n",
        "for b in sorted_betweenness[:20]:\r\n",
        "    print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kl02-javAGv"
      },
      "source": [
        "Well, it is very expected that nodes with high degrees would have high centrality but it would be more interesting to see if there are any noes with low degrees and high centrality. Below we append both attributes to investigate this hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvunIwmePs0-"
      },
      "source": [
        "#First get the top 20 nodes by betweenness as a list\r\n",
        "top_betweenness = sorted_betweenness[:20]\r\n",
        "\r\n",
        "#Then find and print their degree\r\n",
        "for tb in top_betweenness: # Loop through top_betweenness\r\n",
        "    degree = degree_dict[tb[0]] # Use degree_dict to access a node's degree,\r\n",
        "    print(\"Name:\", tb[0], \"| Betweenness Centrality:\", tb[1], \"| Degree:\", degree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHVZICbA03i6"
      },
      "source": [
        "###PART 3: Nodes Removal \r\n",
        "In this section we try to remove a set of nodes one by one to see how it affects the robustness of the network ( ofc we can use the reduced networks to compare which one disconnectes faster. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgLnl50C1O3B"
      },
      "source": [
        "Here we can consider just the Hate comments subgraph and start removing the nodes with highest degrees first, then we do the same for non hate speech comments. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWnCxEGPXrWN",
        "outputId": "05463a03-46d1-4586-fa0c-6da39f9dfcc6"
      },
      "source": [
        "#Select Subgraph based on Negative Emotions for example\r\n",
        "hate_comments_words = [n for n,v in G.nodes(data=True) if v.get(\"hate\",None) != 0]  \r\n",
        "#print (hate_comments_words) #Americano is a positive emotion lol\r\n",
        "print( len(hate_comments_words))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTQ0rqTJuZEu",
        "outputId": "5a8b0046-7491-46df-8118-0edb21220136"
      },
      "source": [
        "nhate_comments_words = [n for n,v in G.nodes(data=True) if v.get(\"hate\",None) == 0]  \r\n",
        "#print (nhate_comments_words) #Americano is a positive emotion lol\r\n",
        "print( len(nhate_comments_words))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi6pQmNiZRwb"
      },
      "source": [
        "#Creating Subgraphs: 1- Hate comments 2- Non hate comments\r\n",
        "hateG = G.subgraph(hate_comments_words)\r\n",
        "nhateG = G.subgraph(nhate_comments_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELsknEx8Fol3"
      },
      "source": [
        "#Here we select the nodes of hate comments subgraph and sort them by degree\r\n",
        "from operator import itemgetter\r\n",
        "degree_dict = dict(hateG.degree(hateG.nodes()))\r\n",
        "nx.set_node_attributes(hateG, degree_dict, 'degree')\r\n",
        "sorted_degree_hateG= sorted(degree_dict.items(), key=itemgetter(1), reverse=True)\r\n",
        "selected_nodes = list(sorted_degree_hateG)[:20] #20 nodes to be removed just for simplicity you can choose any number\r\n",
        "#TOP 20 nodes to remove\r\n",
        "nodes_removed = []\r\n",
        "for i,v in enumerate(selected_nodes): \r\n",
        "  nodes_removed.append(selected_nodes[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHCUBbqzD9Mp"
      },
      "source": [
        "#Node Removal, for robustness, removing 1 by 1 starting by nodes with highest degrees\r\n",
        "G1 = hateG.copy()\r\n",
        "list_transitivity = [] #We can check density too\r\n",
        "#list_degree = []\r\n",
        "#diam_list =[]\r\n",
        "nodes_rem = []\r\n",
        "for i, node in enumerate(nodes_removed):\r\n",
        "  G1.remove_node(node)\r\n",
        "  #diam_list.append(nx.diameter(G1.to_undirected()) ) #returns an error \r\n",
        "  list_transitivity.append(nx.transitivity(G1)) #we can use it to measure robustness\r\n",
        "  nodes_rem.append(i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjAtRaskILJC"
      },
      "source": [
        "plt.plot(nodes_rem, list_transitivity, 'r-')\r\n",
        "#plt.plot(nodes_removed, diam_list , 'b-')\r\n",
        "plt.ylabel(\"transitivity\")\r\n",
        "plt.xlabel(\"Removed nodes\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnlTbyFL24up"
      },
      "source": [
        "**The above code can be repeated on another subset of data**"
      ]
    }
  ]
}