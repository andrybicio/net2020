{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Import\n",
    "#########\n",
    "import re\n",
    "import regex\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the csv file with all the comments and post togheter\n",
    "comDB = pd.read_csv(r\"database/com_liwc.csv\", sep='\\t', engine='python', encoding='utf-8')\n",
    "\n",
    "# import the csv file with JUST the politicians post\n",
    "postDB = pd.read_csv(r\"database/postDB.csv\", engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Data Frame\n",
    "#df = pd.DataFrame(data=comDB)\n",
    "df_post = pd.DataFrame(data=postDB)\n",
    "\n",
    "# add a new colum with sequence numbers\n",
    "#df['Count']=1\n",
    "df_post['Count']=1\n",
    "\n",
    "# print all the DF\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_row', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Origin_file_order</th>\n",
       "      <th>Site</th>\n",
       "      <th>p_id</th>\n",
       "      <th>dateCreated</th>\n",
       "      <th>p_politician</th>\n",
       "      <th>p_gender</th>\n",
       "      <th>p_GRUPPO_PE</th>\n",
       "      <th>p_LISTA</th>\n",
       "      <th>p_PARTITO</th>\n",
       "      <th>p_governo</th>\n",
       "      <th>p_dx_sx</th>\n",
       "      <th>p_CIRCOSCRIZIONE</th>\n",
       "      <th>p_text</th>\n",
       "      <th>p_favoriteCount</th>\n",
       "      <th>p_shareCount</th>\n",
       "      <th>p_replyCount</th>\n",
       "      <th>p_replyEval</th>\n",
       "      <th>p_numComments</th>\n",
       "      <th>p_numFakeTags</th>\n",
       "      <th>p_rating</th>\n",
       "      <th>p_category</th>\n",
       "      <th>p_topic</th>\n",
       "      <th>p_campagna</th>\n",
       "      <th>p_camapagna2</th>\n",
       "      <th>Target1</th>\n",
       "      <th>Target2</th>\n",
       "      <th>p_targe1-2</th>\n",
       "      <th>target1_s-p</th>\n",
       "      <th>target1_pol</th>\n",
       "      <th>c_text</th>\n",
       "      <th>c_level</th>\n",
       "      <th>c_replyToUser</th>\n",
       "      <th>c_replyToText</th>\n",
       "      <th>c_rating</th>\n",
       "      <th>c_rating3</th>\n",
       "      <th>c_ratingCivile</th>\n",
       "      <th>c_ratingPosNeg</th>\n",
       "      <th>c_category</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>c_topic</th>\n",
       "      <th>isPersonal</th>\n",
       "      <th>c_WC</th>\n",
       "      <th>c_WPS</th>\n",
       "      <th>c_Sixltr</th>\n",
       "      <th>c_Dic</th>\n",
       "      <th>c_pronomi</th>\n",
       "      <th>c_Io</th>\n",
       "      <th>c_Noi</th>\n",
       "      <th>c_Se</th>\n",
       "      <th>c_Tu</th>\n",
       "      <th>c_Altri</th>\n",
       "      <th>c_Negazio</th>\n",
       "      <th>c_Consen</th>\n",
       "      <th>c_Articol</th>\n",
       "      <th>c_Prepos</th>\n",
       "      <th>c_Numero</th>\n",
       "      <th>c_Affett</th>\n",
       "      <th>c_Sen_Pos</th>\n",
       "      <th>c_Emo_Pos</th>\n",
       "      <th>c_Ottimis</th>\n",
       "      <th>c_Emo_Neg</th>\n",
       "      <th>c_Ansia</th>\n",
       "      <th>c_Rabbia</th>\n",
       "      <th>c_Tristez</th>\n",
       "      <th>c_Mec_Cog</th>\n",
       "      <th>c_Causa</th>\n",
       "      <th>c_Intros</th>\n",
       "      <th>c_Discrep</th>\n",
       "      <th>c_Inibiz</th>\n",
       "      <th>c_possib</th>\n",
       "      <th>c_Certez</th>\n",
       "      <th>c_Proc_Sen</th>\n",
       "      <th>c_Vista</th>\n",
       "      <th>c_Udito</th>\n",
       "      <th>c_Sentim</th>\n",
       "      <th>c_Social</th>\n",
       "      <th>c_Comm</th>\n",
       "      <th>c_Rif_gen</th>\n",
       "      <th>c_amici</th>\n",
       "      <th>c_Famigl</th>\n",
       "      <th>c_Umano</th>\n",
       "      <th>c_Tempo</th>\n",
       "      <th>c_Passato</th>\n",
       "      <th>c_Present</th>\n",
       "      <th>c_Futuro</th>\n",
       "      <th>c_Spazio</th>\n",
       "      <th>c_Sopra</th>\n",
       "      <th>c_Sotto</th>\n",
       "      <th>c_Inclusi</th>\n",
       "      <th>c_Esclusi</th>\n",
       "      <th>c_Movimen</th>\n",
       "      <th>c_Occupaz</th>\n",
       "      <th>c_Scuola</th>\n",
       "      <th>c_Lavoro</th>\n",
       "      <th>c_Raggiun</th>\n",
       "      <th>c_Svago</th>\n",
       "      <th>c_Casa</th>\n",
       "      <th>c_Sport</th>\n",
       "      <th>c_TV_it</th>\n",
       "      <th>c_Musica</th>\n",
       "      <th>c_Soldi</th>\n",
       "      <th>c_Metafis</th>\n",
       "      <th>c_religio</th>\n",
       "      <th>c_Morte</th>\n",
       "      <th>c_Fisico</th>\n",
       "      <th>c_Corpo</th>\n",
       "      <th>c_Sesso</th>\n",
       "      <th>c_Mangiare</th>\n",
       "      <th>c_Dormire</th>\n",
       "      <th>c_Cura_cor</th>\n",
       "      <th>c_parolac</th>\n",
       "      <th>c_Non_flu</th>\n",
       "      <th>c_riempiti</th>\n",
       "      <th>c_Voi</th>\n",
       "      <th>c_Lui_lei</th>\n",
       "      <th>c_Loro</th>\n",
       "      <th>c_Condizio</th>\n",
       "      <th>c_Transiti</th>\n",
       "      <th>c_P_pass</th>\n",
       "      <th>c_gerundio</th>\n",
       "      <th>c_Passivo</th>\n",
       "      <th>c_Essere</th>\n",
       "      <th>c_Avere</th>\n",
       "      <th>c_Formale</th>\n",
       "      <th>c_Io_Ver</th>\n",
       "      <th>c_Tu_Verbo</th>\n",
       "      <th>c_Lui_Verb</th>\n",
       "      <th>c_Noi_Verb</th>\n",
       "      <th>c_Voi_Verb</th>\n",
       "      <th>c_Loro_Ver</th>\n",
       "      <th>c_AllPunc</th>\n",
       "      <th>c_Period</th>\n",
       "      <th>c_Comma</th>\n",
       "      <th>c_Colon</th>\n",
       "      <th>c_SemiC</th>\n",
       "      <th>c_Qmark</th>\n",
       "      <th>c_Exclam</th>\n",
       "      <th>c_Dash</th>\n",
       "      <th>c_Quote</th>\n",
       "      <th>c_Apostro</th>\n",
       "      <th>c_Parenth</th>\n",
       "      <th>c_OtherP</th>\n",
       "      <th>p_WC</th>\n",
       "      <th>p_WPS</th>\n",
       "      <th>p_Sixltr</th>\n",
       "      <th>p_Dic</th>\n",
       "      <th>p_pronomi</th>\n",
       "      <th>p_Io</th>\n",
       "      <th>p_Noi</th>\n",
       "      <th>p_Se</th>\n",
       "      <th>p_Tu</th>\n",
       "      <th>p_Altri</th>\n",
       "      <th>p_Negazio</th>\n",
       "      <th>p_Consen</th>\n",
       "      <th>p_Articol</th>\n",
       "      <th>p_Prepos</th>\n",
       "      <th>p_Numero</th>\n",
       "      <th>p_Affett</th>\n",
       "      <th>p_Sen_Pos</th>\n",
       "      <th>p_Emo_Pos</th>\n",
       "      <th>p_Ottimis</th>\n",
       "      <th>p_Emo_Neg</th>\n",
       "      <th>p_Ansia</th>\n",
       "      <th>p_Rabbia</th>\n",
       "      <th>p_Tristez</th>\n",
       "      <th>p_Mec_Cog</th>\n",
       "      <th>p_Causa</th>\n",
       "      <th>Ip_ntros</th>\n",
       "      <th>p_Discrep</th>\n",
       "      <th>Ip_nibiz</th>\n",
       "      <th>p_possib</th>\n",
       "      <th>p_Certez</th>\n",
       "      <th>p_Proc_Sen</th>\n",
       "      <th>p_Vista</th>\n",
       "      <th>p_Udito</th>\n",
       "      <th>p_Sentim</th>\n",
       "      <th>p_Social</th>\n",
       "      <th>p_Comm</th>\n",
       "      <th>p_Rif_gen</th>\n",
       "      <th>p_amici</th>\n",
       "      <th>p_Famigl</th>\n",
       "      <th>p_Umano</th>\n",
       "      <th>p_Tempo</th>\n",
       "      <th>p_Passato</th>\n",
       "      <th>p_Present</th>\n",
       "      <th>p_Futuro</th>\n",
       "      <th>p_Spazio</th>\n",
       "      <th>p_Sopra</th>\n",
       "      <th>p_Sotto</th>\n",
       "      <th>Ip_nclusi</th>\n",
       "      <th>p_Esclusi</th>\n",
       "      <th>p_Movimen</th>\n",
       "      <th>p_Occupaz</th>\n",
       "      <th>p_Scuola</th>\n",
       "      <th>p_Lavoro</th>\n",
       "      <th>p_Raggiun</th>\n",
       "      <th>p_Svago</th>\n",
       "      <th>p_Casa</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_TV_it</th>\n",
       "      <th>p_Musica</th>\n",
       "      <th>p_Soldi</th>\n",
       "      <th>p_Metafis</th>\n",
       "      <th>p_religio</th>\n",
       "      <th>p_Morte</th>\n",
       "      <th>p_Fisico</th>\n",
       "      <th>p_Corpo</th>\n",
       "      <th>p_Sesso</th>\n",
       "      <th>p_Mangiare</th>\n",
       "      <th>p_Dormire</th>\n",
       "      <th>p_Cura_cor</th>\n",
       "      <th>p_parolac</th>\n",
       "      <th>p_Non_flu</th>\n",
       "      <th>p_riempiti</th>\n",
       "      <th>p_Voi</th>\n",
       "      <th>p_Lui_lei</th>\n",
       "      <th>p_Loro</th>\n",
       "      <th>p_Condizio</th>\n",
       "      <th>p_Transiti</th>\n",
       "      <th>p_P_pass</th>\n",
       "      <th>p_gerundio</th>\n",
       "      <th>p_Passivo</th>\n",
       "      <th>p_Essere</th>\n",
       "      <th>p_Avere</th>\n",
       "      <th>p_Formale</th>\n",
       "      <th>p_Io_Ver</th>\n",
       "      <th>p_Tu_Verbo</th>\n",
       "      <th>p_Lui_Verb</th>\n",
       "      <th>p_Noi_Verb</th>\n",
       "      <th>p_Voi_Verb</th>\n",
       "      <th>p_Loro_Ver</th>\n",
       "      <th>p_AllPunc</th>\n",
       "      <th>p_Period</th>\n",
       "      <th>p_Comma</th>\n",
       "      <th>p_Colon</th>\n",
       "      <th>p_SemiC</th>\n",
       "      <th>p_Qmark</th>\n",
       "      <th>p_Exclam</th>\n",
       "      <th>p_Dash</th>\n",
       "      <th>p_Quote</th>\n",
       "      <th>p_Apostro</th>\n",
       "      <th>p_Parenth</th>\n",
       "      <th>p_OtherP</th>\n",
       "      <th>Count</th>\n",
       "      <th>target1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30126</td>\n",
       "      <td>FB</td>\n",
       "      <td>96844400700_10157493758850701</td>\n",
       "      <td>2019-04-23T10:33:37Z</td>\n",
       "      <td>MARCELLO GEMMATO</td>\n",
       "      <td>M</td>\n",
       "      <td>PPE</td>\n",
       "      <td>FDI</td>\n",
       "      <td>FDI</td>\n",
       "      <td>opposizione</td>\n",
       "      <td>destra</td>\n",
       "      <td>s</td>\n",
       "      <td>Se i musulmani pensano di portare la guerra sa...</td>\n",
       "      <td>270</td>\n",
       "      <td>80</td>\n",
       "      <td>57</td>\n",
       "      <td>33</td>\n",
       "      <td>1729</td>\n",
       "      <td>0</td>\n",
       "      <td>problematico</td>\n",
       "      <td>Rifugiati Musulmani</td>\n",
       "      <td>religioni europa</td>\n",
       "      <td>Comparativa</td>\n",
       "      <td>Neg-comp</td>\n",
       "      <td>Categoria di persone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Categoria di persone</td>\n",
       "      <td>gruppo</td>\n",
       "      <td>non politico</td>\n",
       "      <td>C'è poco da dire questa è gente che la guerra ...</td>\n",
       "      <td>1</td>\n",
       "      <td>FRATELLIDITALIA.PUGLIA</td>\n",
       "      <td>Se i musulmani pensano di portare la guerra sa...</td>\n",
       "      <td>problematico</td>\n",
       "      <td>probl-hate</td>\n",
       "      <td>incivile</td>\n",
       "      <td>negativo</td>\n",
       "      <td>Rifugiati Musulmani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>2.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>53320</td>\n",
       "      <td>FB</td>\n",
       "      <td>911961728894076_2169530686470501</td>\n",
       "      <td>2019-04-17T12:50:26Z</td>\n",
       "      <td>IGOR GELARDA</td>\n",
       "      <td>M</td>\n",
       "      <td>EFDD</td>\n",
       "      <td>LEGA</td>\n",
       "      <td>Lega</td>\n",
       "      <td>governo</td>\n",
       "      <td>destra</td>\n",
       "      <td>i</td>\n",
       "      <td>Un mio particolare ringraziamento va ai Magist...</td>\n",
       "      <td>69</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>6565</td>\n",
       "      <td>0</td>\n",
       "      <td>positivo</td>\n",
       "      <td>None</td>\n",
       "      <td>Other</td>\n",
       "      <td>Comparativa</td>\n",
       "      <td>Neg-comp</td>\n",
       "      <td>Categoria di persone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Categoria di persone</td>\n",
       "      <td>gruppo</td>\n",
       "      <td>non politico</td>\n",
       "      <td>Escremento umano!</td>\n",
       "      <td>1</td>\n",
       "      <td>gelardaigor</td>\n",
       "      <td>Un mio particolare ringraziamento va ai Magist...</td>\n",
       "      <td>problematico</td>\n",
       "      <td>probl-hate</td>\n",
       "      <td>incivile</td>\n",
       "      <td>negativo</td>\n",
       "      <td>Rifugiati</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>49</td>\n",
       "      <td>24.50</td>\n",
       "      <td>16.33</td>\n",
       "      <td>63.27</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.24</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.16</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>4.08</td>\n",
       "      <td>12.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.16</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.45</td>\n",
       "      <td>14.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>21.00</td>\n",
       "      <td>23.81</td>\n",
       "      <td>54.76</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.90</td>\n",
       "      <td>14.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.76</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.14</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.76</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>4.76</td>\n",
       "      <td>11.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>78041</td>\n",
       "      <td>FB</td>\n",
       "      <td>667483386685540_1869411966492670</td>\n",
       "      <td>2019-05-21T15:13:32Z</td>\n",
       "      <td>SILVIA SERAFINA DETTA NARDONE SARDONE</td>\n",
       "      <td>F</td>\n",
       "      <td>EFDD</td>\n",
       "      <td>LEGA</td>\n",
       "      <td>Lega</td>\n",
       "      <td>governo</td>\n",
       "      <td>destra</td>\n",
       "      <td>no</td>\n",
       "      <td>Minacce, insulti, scontri in piazza per blocca...</td>\n",
       "      <td>2121</td>\n",
       "      <td>643</td>\n",
       "      <td>702</td>\n",
       "      <td>1</td>\n",
       "      <td>113152</td>\n",
       "      <td>0</td>\n",
       "      <td>positivo</td>\n",
       "      <td>None</td>\n",
       "      <td>europa altroPolitico</td>\n",
       "      <td>Comparativa</td>\n",
       "      <td>Neg-comp</td>\n",
       "      <td>Categoria di persone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Categoria di persone</td>\n",
       "      <td>gruppo</td>\n",
       "      <td>non politico</td>\n",
       "      <td>Se l'infilino nei loro culetti antifa a mo di ...</td>\n",
       "      <td>1</td>\n",
       "      <td>silviasardone</td>\n",
       "      <td>Minacce, insulti, scontri in piazza per blocca...</td>\n",
       "      <td>problematico</td>\n",
       "      <td>probl-hate</td>\n",
       "      <td>incivile</td>\n",
       "      <td>negativo</td>\n",
       "      <td>Altro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>politico</td>\n",
       "      <td>Yes Other_pol</td>\n",
       "      <td>47</td>\n",
       "      <td>15.67</td>\n",
       "      <td>31.91</td>\n",
       "      <td>59.57</td>\n",
       "      <td>12.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>10.64</td>\n",
       "      <td>10.64</td>\n",
       "      <td>2.13</td>\n",
       "      <td>6.38</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>8.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>2.13</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.77</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.38</td>\n",
       "      <td>2.13</td>\n",
       "      <td>8.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.40</td>\n",
       "      <td>10.64</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>8.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>13.00</td>\n",
       "      <td>30.77</td>\n",
       "      <td>69.23</td>\n",
       "      <td>10.26</td>\n",
       "      <td>5.13</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>20.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.69</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.82</td>\n",
       "      <td>7.69</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.13</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.38</td>\n",
       "      <td>10.26</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>229</td>\n",
       "      <td>FB</td>\n",
       "      <td>667483386685540_1844118159022051</td>\n",
       "      <td>2019-05-05T08:53:55Z</td>\n",
       "      <td>SILVIA SERAFINA DETTA NARDONE SARDONE</td>\n",
       "      <td>F</td>\n",
       "      <td>EFDD</td>\n",
       "      <td>LEGA</td>\n",
       "      <td>Lega</td>\n",
       "      <td>governo</td>\n",
       "      <td>destra</td>\n",
       "      <td>no</td>\n",
       "      <td>Ecco il pensiero dei radical chic di sinistra....</td>\n",
       "      <td>1040</td>\n",
       "      <td>1450</td>\n",
       "      <td>2291</td>\n",
       "      <td>9</td>\n",
       "      <td>113152</td>\n",
       "      <td>0</td>\n",
       "      <td>positivo</td>\n",
       "      <td>None</td>\n",
       "      <td>rifugiati europa</td>\n",
       "      <td>Comparativa</td>\n",
       "      <td>Neg-comp</td>\n",
       "      <td>Categoria di persone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Categoria di persone</td>\n",
       "      <td>gruppo</td>\n",
       "      <td>non politico</td>\n",
       "      <td>pezzo di merda perche non vai via dal italia,s...</td>\n",
       "      <td>1</td>\n",
       "      <td>silviasardone</td>\n",
       "      <td>Ecco il pensiero dei radical chic di sinistra....</td>\n",
       "      <td>problematico</td>\n",
       "      <td>probl-hate</td>\n",
       "      <td>incivile</td>\n",
       "      <td>negativo</td>\n",
       "      <td>Altro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>6</td>\n",
       "      <td>3.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>66.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>33.33</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>31.00</td>\n",
       "      <td>45.16</td>\n",
       "      <td>45.16</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.90</td>\n",
       "      <td>9.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.45</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.48</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>17457</td>\n",
       "      <td>FB</td>\n",
       "      <td>667483386685540_1835929416507592</td>\n",
       "      <td>2019-04-29T15:12:05Z</td>\n",
       "      <td>SILVIA SERAFINA DETTA NARDONE SARDONE</td>\n",
       "      <td>F</td>\n",
       "      <td>EFDD</td>\n",
       "      <td>LEGA</td>\n",
       "      <td>Lega</td>\n",
       "      <td>governo</td>\n",
       "      <td>destra</td>\n",
       "      <td>no</td>\n",
       "      <td>I vermi protagonisti delle ultime violenze sul...</td>\n",
       "      <td>2335</td>\n",
       "      <td>571</td>\n",
       "      <td>445</td>\n",
       "      <td>13</td>\n",
       "      <td>113152</td>\n",
       "      <td>0</td>\n",
       "      <td>negativo</td>\n",
       "      <td>None</td>\n",
       "      <td>Other</td>\n",
       "      <td>Comparativa</td>\n",
       "      <td>Neg-comp</td>\n",
       "      <td>Categoria di persone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Categoria di persone</td>\n",
       "      <td>gruppo</td>\n",
       "      <td>non politico</td>\n",
       "      <td>Anche non chimica ,basta castrare</td>\n",
       "      <td>1</td>\n",
       "      <td>silviasardone</td>\n",
       "      <td>I vermi protagonisti delle ultime violenze sul...</td>\n",
       "      <td>problematico</td>\n",
       "      <td>probl-hate</td>\n",
       "      <td>incivile</td>\n",
       "      <td>negativo</td>\n",
       "      <td>Altro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>politico</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>429</td>\n",
       "      <td>26.81</td>\n",
       "      <td>31.47</td>\n",
       "      <td>38.93</td>\n",
       "      <td>5.36</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.76</td>\n",
       "      <td>5.83</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>30.07</td>\n",
       "      <td>3.50</td>\n",
       "      <td>10.72</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>11.19</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Origin_file_order Site                              p_id  \\\n",
       "0           0              30126   FB     96844400700_10157493758850701   \n",
       "1          15              53320   FB  911961728894076_2169530686470501   \n",
       "2          16              78041   FB  667483386685540_1869411966492670   \n",
       "3          17                229   FB  667483386685540_1844118159022051   \n",
       "4          20              17457   FB  667483386685540_1835929416507592   \n",
       "\n",
       "            dateCreated                           p_politician p_gender  \\\n",
       "0  2019-04-23T10:33:37Z                       MARCELLO GEMMATO        M   \n",
       "1  2019-04-17T12:50:26Z                           IGOR GELARDA        M   \n",
       "2  2019-05-21T15:13:32Z  SILVIA SERAFINA DETTA NARDONE SARDONE        F   \n",
       "3  2019-05-05T08:53:55Z  SILVIA SERAFINA DETTA NARDONE SARDONE        F   \n",
       "4  2019-04-29T15:12:05Z  SILVIA SERAFINA DETTA NARDONE SARDONE        F   \n",
       "\n",
       "  p_GRUPPO_PE p_LISTA p_PARTITO    p_governo p_dx_sx p_CIRCOSCRIZIONE  \\\n",
       "0         PPE     FDI       FDI  opposizione  destra                s   \n",
       "1        EFDD    LEGA      Lega      governo  destra                i   \n",
       "2        EFDD    LEGA      Lega      governo  destra               no   \n",
       "3        EFDD    LEGA      Lega      governo  destra               no   \n",
       "4        EFDD    LEGA      Lega      governo  destra               no   \n",
       "\n",
       "                                              p_text  p_favoriteCount  \\\n",
       "0  Se i musulmani pensano di portare la guerra sa...              270   \n",
       "1  Un mio particolare ringraziamento va ai Magist...               69   \n",
       "2  Minacce, insulti, scontri in piazza per blocca...             2121   \n",
       "3  Ecco il pensiero dei radical chic di sinistra....             1040   \n",
       "4  I vermi protagonisti delle ultime violenze sul...             2335   \n",
       "\n",
       "   p_shareCount  p_replyCount  p_replyEval  p_numComments  p_numFakeTags  \\\n",
       "0            80            57           33           1729              0   \n",
       "1            33            14            5           6565              0   \n",
       "2           643           702            1         113152              0   \n",
       "3          1450          2291            9         113152              0   \n",
       "4           571           445           13         113152              0   \n",
       "\n",
       "       p_rating           p_category               p_topic   p_campagna  \\\n",
       "0  problematico  Rifugiati Musulmani      religioni europa  Comparativa   \n",
       "1      positivo                 None                 Other  Comparativa   \n",
       "2      positivo                 None  europa altroPolitico  Comparativa   \n",
       "3      positivo                 None      rifugiati europa  Comparativa   \n",
       "4      negativo                 None                 Other  Comparativa   \n",
       "\n",
       "  p_camapagna2               Target1 Target2             p_targe1-2  \\\n",
       "0     Neg-comp  Categoria di persone     NaN  Categoria di persone    \n",
       "1     Neg-comp  Categoria di persone     NaN  Categoria di persone    \n",
       "2     Neg-comp  Categoria di persone     NaN  Categoria di persone    \n",
       "3     Neg-comp  Categoria di persone     NaN  Categoria di persone    \n",
       "4     Neg-comp  Categoria di persone     NaN  Categoria di persone    \n",
       "\n",
       "  target1_s-p   target1_pol  \\\n",
       "0      gruppo  non politico   \n",
       "1      gruppo  non politico   \n",
       "2      gruppo  non politico   \n",
       "3      gruppo  non politico   \n",
       "4      gruppo  non politico   \n",
       "\n",
       "                                              c_text  c_level  \\\n",
       "0  C'è poco da dire questa è gente che la guerra ...        1   \n",
       "1                                  Escremento umano!        1   \n",
       "2  Se l'infilino nei loro culetti antifa a mo di ...        1   \n",
       "3  pezzo di merda perche non vai via dal italia,s...        1   \n",
       "4                  Anche non chimica ,basta castrare        1   \n",
       "\n",
       "            c_replyToUser                                      c_replyToText  \\\n",
       "0  FRATELLIDITALIA.PUGLIA  Se i musulmani pensano di portare la guerra sa...   \n",
       "1             gelardaigor  Un mio particolare ringraziamento va ai Magist...   \n",
       "2           silviasardone  Minacce, insulti, scontri in piazza per blocca...   \n",
       "3           silviasardone  Ecco il pensiero dei radical chic di sinistra....   \n",
       "4           silviasardone  I vermi protagonisti delle ultime violenze sul...   \n",
       "\n",
       "       c_rating   c_rating3 c_ratingCivile c_ratingPosNeg  \\\n",
       "0  problematico  probl-hate       incivile       negativo   \n",
       "1  problematico  probl-hate       incivile       negativo   \n",
       "2  problematico  probl-hate       incivile       negativo   \n",
       "3  problematico  probl-hate       incivile       negativo   \n",
       "4  problematico  probl-hate       incivile       negativo   \n",
       "\n",
       "            c_category  Unnamed: 38   c_topic     isPersonal  c_WC  c_WPS  \\\n",
       "0  Rifugiati Musulmani          NaN     Other          Other     4   2.00   \n",
       "1            Rifugiati          NaN     Other          Other    49  24.50   \n",
       "2                Altro          NaN  politico  Yes Other_pol    47  15.67   \n",
       "3                Altro          NaN     Other          Other     6   3.00   \n",
       "4                Altro          NaN  politico          Other     4   4.00   \n",
       "\n",
       "   c_Sixltr  c_Dic  c_pronomi  c_Io  c_Noi  c_Se  c_Tu  c_Altri  c_Negazio  \\\n",
       "0     50.00   0.00       0.00   0.0   0.00  0.00   0.0     0.00       0.00   \n",
       "1     16.33  63.27       6.12   0.0   2.04  2.04   0.0     0.00       4.08   \n",
       "2     31.91  59.57      12.77   0.0   0.00  0.00   0.0     2.13       0.00   \n",
       "3     16.67  66.67       0.00   0.0   0.00  0.00   0.0     0.00       0.00   \n",
       "4     25.00  75.00      25.00   0.0   0.00  0.00   0.0     0.00       0.00   \n",
       "\n",
       "   c_Consen  c_Articol  c_Prepos  c_Numero  c_Affett  c_Sen_Pos  c_Emo_Pos  \\\n",
       "0      0.00       0.00      0.00      0.00      0.00       0.00       0.00   \n",
       "1      0.00      12.24      6.12      0.00      8.16       4.08       4.08   \n",
       "2      2.13      10.64     10.64      2.13      6.38       2.13       0.00   \n",
       "3      0.00       0.00      0.00      0.00     16.67       0.00       0.00   \n",
       "4      0.00      25.00      0.00      0.00     25.00      25.00       0.00   \n",
       "\n",
       "   c_Ottimis  c_Emo_Neg  c_Ansia  c_Rabbia  c_Tristez  c_Mec_Cog  c_Causa  \\\n",
       "0       0.00       0.00      0.0      0.00       0.00       0.00      0.0   \n",
       "1       0.00       4.08      0.0      0.00       4.08       4.08      0.0   \n",
       "2       2.13       4.26      0.0      0.00       2.13       8.51      0.0   \n",
       "3       0.00      16.67      0.0     16.67       0.00      16.67      0.0   \n",
       "4       0.00       0.00      0.0      0.00       0.00       0.00      0.0   \n",
       "\n",
       "   c_Intros  c_Discrep  c_Inibiz  c_possib  c_Certez  c_Proc_Sen  c_Vista  \\\n",
       "0      0.00       0.00       0.0      0.00       0.0        0.00     0.00   \n",
       "1      2.04       0.00       0.0      6.12       0.0        2.04     2.04   \n",
       "2      2.13       6.38       0.0      4.26       0.0        2.13     0.00   \n",
       "3      0.00       0.00       0.0      0.00       0.0        0.00     0.00   \n",
       "4      0.00       0.00       0.0      0.00       0.0        0.00     0.00   \n",
       "\n",
       "   c_Udito  c_Sentim  c_Social  c_Comm  c_Rif_gen  c_amici  c_Famigl  c_Umano  \\\n",
       "0     0.00       0.0      0.00    0.00       0.00     0.00       0.0      0.0   \n",
       "1     0.00       0.0      6.12    0.00       0.00     4.08       0.0      0.0   \n",
       "2     2.13       0.0      4.26    2.13       6.38     0.00       0.0      0.0   \n",
       "3     0.00       0.0      0.00    0.00       0.00     0.00       0.0      0.0   \n",
       "4     0.00       0.0      0.00    0.00       0.00     0.00       0.0      0.0   \n",
       "\n",
       "   c_Tempo  c_Passato  c_Present  c_Futuro  c_Spazio  c_Sopra  c_Sotto  \\\n",
       "0     0.00       0.00       0.00      0.00       0.0      0.0      0.0   \n",
       "1     6.12       4.08      12.24      0.00       0.0      0.0      0.0   \n",
       "2     0.00       0.00      12.77      4.26       0.0      0.0      0.0   \n",
       "3     0.00       0.00      33.33      0.00       0.0      0.0      0.0   \n",
       "4     0.00       0.00       0.00      0.00       0.0      0.0      0.0   \n",
       "\n",
       "   c_Inclusi  c_Esclusi  c_Movimen  c_Occupaz  c_Scuola  c_Lavoro  c_Raggiun  \\\n",
       "0       0.00       0.00       0.00        0.0       0.0       0.0       0.00   \n",
       "1       0.00       8.16       2.04        0.0       0.0       0.0       0.00   \n",
       "2       0.00       6.38       0.00        0.0       0.0       0.0       2.13   \n",
       "3      16.67       0.00       0.00        0.0       0.0       0.0       0.00   \n",
       "4       0.00      25.00       0.00       25.0       0.0       0.0      25.00   \n",
       "\n",
       "   c_Svago  c_Casa  c_Sport  c_TV_it  c_Musica  c_Soldi  c_Metafis  c_religio  \\\n",
       "0      0.0     0.0      0.0      0.0       0.0     0.00        0.0        0.0   \n",
       "1      0.0     0.0      0.0      0.0       0.0     2.04        0.0        0.0   \n",
       "2      0.0     0.0      0.0      0.0       0.0     0.00        0.0        0.0   \n",
       "3      0.0     0.0      0.0      0.0       0.0     0.00        0.0        0.0   \n",
       "4      0.0     0.0      0.0      0.0       0.0     0.00        0.0        0.0   \n",
       "\n",
       "   c_Morte  c_Fisico  c_Corpo  c_Sesso  c_Mangiare  c_Dormire  c_Cura_cor  \\\n",
       "0      0.0      0.00     0.00      0.0         0.0        0.0         0.0   \n",
       "1      0.0      0.00     0.00      0.0         0.0        0.0         0.0   \n",
       "2      0.0      2.13     2.13      0.0         0.0        0.0         0.0   \n",
       "3      0.0      0.00     0.00      0.0         0.0        0.0         0.0   \n",
       "4      0.0      0.00     0.00      0.0         0.0        0.0         0.0   \n",
       "\n",
       "   c_parolac  c_Non_flu  c_riempiti  c_Voi  c_Lui_lei  c_Loro  c_Condizio  \\\n",
       "0        0.0        0.0        0.00    0.0       0.00     0.0         0.0   \n",
       "1        0.0        0.0        0.00    0.0       0.00     0.0         0.0   \n",
       "2        0.0        0.0        2.13    0.0       4.26     0.0         0.0   \n",
       "3        0.0        0.0        0.00    0.0       0.00     0.0         0.0   \n",
       "4        0.0        0.0        0.00    0.0       0.00     0.0         0.0   \n",
       "\n",
       "   c_Transiti  c_P_pass  c_gerundio  c_Passivo  c_Essere  c_Avere  c_Formale  \\\n",
       "0        0.00      0.00         0.0          0      0.00     0.00          0   \n",
       "1        0.00      4.08         0.0          0      2.04     2.04          0   \n",
       "2        2.13      0.00         0.0          0      2.13     0.00          0   \n",
       "3        0.00      0.00         0.0          0      0.00     0.00          0   \n",
       "4        0.00      0.00         0.0          0      0.00     0.00          0   \n",
       "\n",
       "   c_Io_Ver  c_Tu_Verbo  c_Lui_Verb  c_Noi_Verb  c_Voi_Verb  c_Loro_Ver  \\\n",
       "0       0.0         0.0        0.00        0.00        0.00        0.00   \n",
       "1       0.0         0.0        6.12        2.04        0.00        0.00   \n",
       "2       0.0         0.0        6.38        2.13        8.51        0.00   \n",
       "3       0.0         0.0        0.00        0.00        0.00       16.67   \n",
       "4       0.0         0.0        0.00        0.00        0.00        0.00   \n",
       "\n",
       "   c_AllPunc  c_Period  c_Comma  c_Colon  c_SemiC  c_Qmark  c_Exclam  c_Dash  \\\n",
       "0     125.00    100.00     0.00      0.0     0.00     0.00     25.00     0.0   \n",
       "1      22.45     14.29     0.00      0.0     0.00     0.00      6.12     0.0   \n",
       "2      23.40     10.64     2.13      0.0     2.13     8.51      0.00     0.0   \n",
       "3      33.33     33.33     0.00      0.0     0.00     0.00      0.00     0.0   \n",
       "4       0.00      0.00     0.00      0.0     0.00     0.00      0.00     0.0   \n",
       "\n",
       "   c_Quote  c_Apostro  c_Parenth  c_OtherP  p_WC  p_WPS  p_Sixltr  p_Dic  \\\n",
       "0      0.0       0.00        0.0       0.0     6   6.00     33.33  33.33   \n",
       "1      0.0       2.04        0.0       0.0    42  21.00     23.81  54.76   \n",
       "2      0.0       0.00        0.0       0.0    39  13.00     30.77  69.23   \n",
       "3      0.0       0.00        0.0       0.0    31  31.00     45.16  45.16   \n",
       "4      0.0       0.00        0.0       0.0   429  26.81     31.47  38.93   \n",
       "\n",
       "   p_pronomi  p_Io  p_Noi  p_Se  p_Tu  p_Altri  p_Negazio  p_Consen  \\\n",
       "0       0.00  0.00   0.00  0.00   0.0      0.0        0.0       0.0   \n",
       "1       4.76  0.00   0.00  0.00   0.0      0.0        0.0       0.0   \n",
       "2      10.26  5.13   2.56  0.00   0.0      0.0        0.0       0.0   \n",
       "3       3.23  3.23   0.00  0.00   0.0      0.0        0.0       0.0   \n",
       "4       5.36  2.56   0.93  1.86   0.0      0.0        1.4       0.0   \n",
       "\n",
       "   p_Articol  p_Prepos  p_Numero  p_Affett  p_Sen_Pos  p_Emo_Pos  p_Ottimis  \\\n",
       "0       0.00     33.33      0.00      0.00       0.00        0.0       0.00   \n",
       "1      11.90     14.29      0.00      2.38       2.38        0.0       0.00   \n",
       "2       5.13     20.51      0.00      7.69       7.69        0.0       2.56   \n",
       "3      12.90      9.68      0.00      6.45       0.00        0.0       0.00   \n",
       "4       6.76      5.83      0.23      3.03       2.10        0.0       0.70   \n",
       "\n",
       "   p_Emo_Neg  p_Ansia  p_Rabbia  p_Tristez  p_Mec_Cog  p_Causa  Ip_ntros  \\\n",
       "0       0.00     0.00       0.0       0.00       0.00     0.00      0.00   \n",
       "1       0.00     0.00       0.0       0.00       2.38     0.00      0.00   \n",
       "2       0.00     0.00       0.0       0.00       7.69     0.00      0.00   \n",
       "3       6.45     3.23       0.0       0.00       3.23     0.00      0.00   \n",
       "4       0.70     0.00       0.0       0.47       4.20     0.47      1.17   \n",
       "\n",
       "   p_Discrep  Ip_nibiz  p_possib  p_Certez  p_Proc_Sen  p_Vista  p_Udito  \\\n",
       "0       0.00       0.0      0.00      0.00        0.00      0.0     0.00   \n",
       "1       0.00       0.0      0.00      0.00        2.38      0.0     2.38   \n",
       "2       5.13       0.0      5.13      0.00        5.13      0.0     5.13   \n",
       "3       0.00       0.0      0.00      0.00        0.00      0.0     0.00   \n",
       "4       0.93       0.7      1.63      0.47        1.40      0.7     0.70   \n",
       "\n",
       "   p_Sentim  p_Social  p_Comm  p_Rif_gen  p_amici  p_Famigl  p_Umano  p_Tempo  \\\n",
       "0       0.0      0.00    0.00       0.00     0.00       0.0     0.00     0.00   \n",
       "1       0.0      4.76    2.38       2.38     0.00       0.0     0.00     0.00   \n",
       "2       0.0     12.82    7.69       2.56     2.56       0.0     0.00     0.00   \n",
       "3       0.0      0.00    0.00       0.00     0.00       0.0     0.00     3.23   \n",
       "4       0.0      3.73    1.86       0.47     0.00       0.0     0.47     1.17   \n",
       "\n",
       "   p_Passato  p_Present  p_Futuro  p_Spazio  p_Sopra  p_Sotto  Ip_nclusi  \\\n",
       "0       0.00       0.00       0.0      0.00      0.0      0.0       0.00   \n",
       "1       2.38       4.76       0.0      0.00      0.0      0.0       7.14   \n",
       "2       5.13       7.69       0.0      0.00      0.0      0.0       2.56   \n",
       "3       0.00       9.68       0.0      0.00      0.0      0.0       0.00   \n",
       "4       0.47       4.66       0.0      0.23      0.0      0.0       0.70   \n",
       "\n",
       "   p_Esclusi  p_Movimen  p_Occupaz  p_Scuola  p_Lavoro  p_Raggiun  p_Svago  \\\n",
       "0       0.00       0.00       0.00       0.0      0.00        0.0     0.00   \n",
       "1       4.76       0.00       0.00       0.0      0.00        0.0     0.00   \n",
       "2       5.13       0.00       2.56       0.0      2.56        0.0     0.00   \n",
       "3       0.00       0.00       0.00       0.0      0.00        0.0     0.00   \n",
       "4       3.03       0.93       0.23       0.0      0.00        0.0     0.47   \n",
       "\n",
       "   p_Casa  p_Sport  p_TV_it  p_Musica  p_Soldi  p_Metafis  p_religio  p_Morte  \\\n",
       "0     0.0      0.0     0.00      0.00     0.00        0.0        0.0      0.0   \n",
       "1     0.0      0.0     0.00      0.00     0.00        0.0        0.0      0.0   \n",
       "2     0.0      0.0     0.00      0.00     0.00        0.0        0.0      0.0   \n",
       "3     0.0      0.0     0.00      0.00     0.00        0.0        0.0      0.0   \n",
       "4     0.0      0.0     0.23      0.23     0.23        0.0        0.0      0.0   \n",
       "\n",
       "   p_Fisico  p_Corpo  p_Sesso  p_Mangiare  p_Dormire  p_Cura_cor  p_parolac  \\\n",
       "0      0.00     0.00      0.0        0.00        0.0         0.0        0.0   \n",
       "1      4.76     4.76      0.0        0.00        0.0         0.0        0.0   \n",
       "2      0.00     0.00      0.0        0.00        0.0         0.0        0.0   \n",
       "3      0.00     0.00      0.0        0.00        0.0         0.0        0.0   \n",
       "4      0.70     0.47      0.0        0.23        0.0         0.0        0.0   \n",
       "\n",
       "   p_Non_flu  p_riempiti  p_Voi  p_Lui_lei  p_Loro  p_Condizio  p_Transiti  \\\n",
       "0        0.0        0.00    0.0        0.0     0.0        0.00        0.00   \n",
       "1        0.0        0.00    0.0        0.0     0.0        0.00        0.00   \n",
       "2        0.0        0.00    0.0        0.0     0.0        0.00        2.56   \n",
       "3        0.0        0.00    0.0        0.0     0.0        3.23        0.00   \n",
       "4        0.0        0.23    0.0        0.0     0.0        1.86        0.23   \n",
       "\n",
       "   p_P_pass  p_gerundio  p_Passivo  p_Essere  p_Avere  p_Formale  p_Io_Ver  \\\n",
       "0      0.00         0.0          0      0.00     0.00          0      0.00   \n",
       "1      2.38         0.0          0      0.00     2.38          0      4.76   \n",
       "2      5.13         0.0          0      2.56     2.56          0      2.56   \n",
       "3      0.00         0.0          0      0.00     3.23          0      0.00   \n",
       "4      2.33         0.0          0      0.93     0.70          0      2.80   \n",
       "\n",
       "   p_Tu_Verbo  p_Lui_Verb  p_Noi_Verb  p_Voi_Verb  p_Loro_Ver  p_AllPunc  \\\n",
       "0         0.0        0.00         0.0        0.00        0.00      16.67   \n",
       "1         0.0        0.00         0.0        0.00        0.00      16.67   \n",
       "2         0.0        0.00         0.0        2.56        2.56      15.38   \n",
       "3         0.0        9.68         0.0        0.00        0.00      35.48   \n",
       "4         0.0        1.40         0.0        0.00        0.23      30.07   \n",
       "\n",
       "   p_Period  p_Comma  p_Colon  p_SemiC  p_Qmark  p_Exclam  p_Dash  p_Quote  \\\n",
       "0     16.67     0.00     0.00      0.0      0.0      0.00    0.00     0.00   \n",
       "1      4.76    11.90     0.00      0.0      0.0      0.00    0.00     0.00   \n",
       "2     10.26     5.13     0.00      0.0      0.0      0.00    0.00     0.00   \n",
       "3      3.23     3.23     3.23      0.0      0.0      0.00    0.00    19.35   \n",
       "4      3.50    10.72     1.17      0.0      0.0      0.47    0.23     0.93   \n",
       "\n",
       "   p_Apostro  p_Parenth  p_OtherP  Count target1_2  \n",
       "0       0.00       0.00      0.00      1       NaN  \n",
       "1       0.00       0.00      0.00      1       NaN  \n",
       "2       0.00       0.00      0.00      1       NaN  \n",
       "3       0.00       6.45      0.00      1       NaN  \n",
       "4       0.93      11.19      0.93      1       NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postDB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posts Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments = df[['c_text']].sample(n=1000, random_state=1).copy() # work with a sample\n",
    "##make a copy of the original df\n",
    "posts = df_post[['p_text']].copy()\n",
    "posts.rename(columns={'p_text':'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Set seed for reproducibility\n",
    "###############################\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 2732\n",
      "Ho capito perché tutti i giorni parlano di #fascismo: hanno bisogno di vendere giornali, libri, riviste. Sono a corto di idee e puntano sull'usato sicuro. Dovrebbero chiedersi perché tanta attenzione su un periodo storico di pochi anni nonostante più di 70 anni di indottrinamento a reti unificate #ScriviMussolini \n",
      "\n",
      "Post 9845\n",
      "Ora in diretta da FAVARA a #lariachetira \n",
      "\n",
      "Post 3264\n",
      "Lui e’ deputato e vicemistro di un governo che ha approvato un piano energia e clima che non rispetta accordi #Onu di #Parigi ,che ha consentito che fanghi di depurazione contenenti diossine possano essere sparsi sui suoli agricoli. #Ipocrisia al governo del paese #sapevatelo https://t.co/xdR9ahi54G \n",
      "\n",
      "Post 4859\n",
      "Ho un brutto carattere (cit) https://t.co/2xPObfzbPz \n",
      "\n",
      "Post 9225\n",
      "Noi andiamo avanti. Siete d'accordo?\n",
      "\n",
      "https://t.co/AIhLqipcvM \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in list(np.random.choice(list(posts.index), 5)):\n",
    "    print(f'Post {i}')\n",
    "    print(posts.loc[i]['text'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_post shape before dropping row: \t (10103, 246)\n",
      "df_post shape after dropping row: \t (10102, 246)\n",
      "Number of Nan in comments text:  0\n"
     ]
    }
   ],
   "source": [
    "###Text pre-processing\n",
    "print('df_post shape before dropping row: \\t', df_post.shape)\n",
    "df_post = df_post[df_post['p_text'].notna()]\n",
    "print('df_post shape after dropping row: \\t', df_post.shape)\n",
    "print('Number of Nan in comments text: ', df_post['p_text'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###make a copy of the original data frame\n",
    "posts[\"text_clean\"] = posts[\"text\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###make the text lower case\n",
    "def lower_casing(text):\n",
    "    return(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(text):\n",
    "    return ' '.join([token for token in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts[\"text_clean\"] = posts[\"text\"].dropna(how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts[\"text_clean\"] = posts[\"text_clean\"].dropna().apply(lambda text: lower_casing(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts[\"text_clean\"] = posts[\"text_clean\"].dropna().apply(lambda text: remove_spaces(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Se i musulmani pensano di portare la guerra sa...</td>\n",
       "      <td>se i musulmani pensano di portare la guerra sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un mio particolare ringraziamento va ai Magist...</td>\n",
       "      <td>un mio particolare ringraziamento va ai magist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>🔴Quasi il 60% degli italiani è favorevole alla...</td>\n",
       "      <td>🔴quasi il 60% degli italiani è favorevole alla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>Il mio intervento ieri sera nella trasmissione...</td>\n",
       "      <td>il mio intervento ieri sera nella trasmissione...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10103 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Se i musulmani pensano di portare la guerra sa...   \n",
       "1      Un mio particolare ringraziamento va ai Magist...   \n",
       "...                                                  ...   \n",
       "10101  🔴Quasi il 60% degli italiani è favorevole alla...   \n",
       "10102  Il mio intervento ieri sera nella trasmissione...   \n",
       "\n",
       "                                              text_clean  \n",
       "0      se i musulmani pensano di portare la guerra sa...  \n",
       "1      un mio particolare ringraziamento va ai magist...  \n",
       "...                                                  ...  \n",
       "10101  🔴quasi il 60% degli italiani è favorevole alla...  \n",
       "10102  il mio intervento ieri sera nella trasmissione...  \n",
       "\n",
       "[10103 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove patterns\n",
    "import re\n",
    "import regex\n",
    "from collections import Counter\n",
    "\n",
    "def remove_patterns(text, patterns):\n",
    "    for pattern in patterns:\n",
    "        try: r = re.findall(pattern, text)\n",
    "        except: r = regex.findall(pattern, text)\n",
    "        for i in r:\n",
    "            try: text = re.sub(re.escape(i), ' ', text)\n",
    "            except: text = regex.sub(regex.escape(i), ' ', text)\n",
    "    return text\n",
    "\n",
    "def pattern_freq(docs, pattern):\n",
    "    p_freq = Counter()\n",
    "    for text in docs:\n",
    "        p_found= re.findall(pattern, text)\n",
    "        for p in p_found:\n",
    "            p_freq[p] += 1\n",
    "    return p_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install emoji\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERNS = {'urls': re.compile(r'https?://\\S+|www\\.\\S+'),\n",
    "            'users': re.compile(r'@[\\w]*'),\n",
    "            #'hashtags': re.compile(r'#[\\w]*'),\n",
    "            'emojis': emoji.get_emoji_regexp(),\n",
    "            'laughs': re.compile(r'\\b(?:(?:hah+|ah+|hah+a|ah+a|lo+l) ?)+\\b'),\n",
    "            'blabla': re.compile(r'\\b(?:(?:bla+) ?)+\\b'),\n",
    "            'dates': re.compile(r'\\b(?:(?:[0-9]+[:\\/,\\.])+[0-9]+)+\\b'),\n",
    "            'digits': r'#\\S+(*SKIP)(*FAIL)|\\b\\d+\\s|\\s\\d+\\s|\\s\\d+|\\b\\d+\\W|\\W\\d+\\W|\\W\\d+$' \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###remove the patterns\n",
    "posts[\"text_clean\"] = posts[\"text_clean\"].dropna().apply(lambda text: remove_patterns(text, PATTERNS.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Se i musulmani pensano di portare la guerra sa...</td>\n",
       "      <td>se i musulmani pensano di portare la guerra sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un mio particolare ringraziamento va ai Magist...</td>\n",
       "      <td>un mio particolare ringraziamento va ai magist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>🔴Quasi il 60% degli italiani è favorevole alla...</td>\n",
       "      <td>quasi il % degli italiani è favorevole alla c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>Il mio intervento ieri sera nella trasmissione...</td>\n",
       "      <td>il mio intervento ieri sera nella trasmissione...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10103 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Se i musulmani pensano di portare la guerra sa...   \n",
       "1      Un mio particolare ringraziamento va ai Magist...   \n",
       "...                                                  ...   \n",
       "10101  🔴Quasi il 60% degli italiani è favorevole alla...   \n",
       "10102  Il mio intervento ieri sera nella trasmissione...   \n",
       "\n",
       "                                              text_clean  \n",
       "0      se i musulmani pensano di portare la guerra sa...  \n",
       "1      un mio particolare ringraziamento va ai magist...  \n",
       "...                                                  ...  \n",
       "10101   quasi il % degli italiani è favorevole alla c...  \n",
       "10102  il mio intervento ieri sera nella trasmissione...  \n",
       "\n",
       "[10103 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Unicode replacer\n",
    "\n",
    "from utils.unicode_replacer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean'] = posts['text_clean'].dropna().apply(lambda text: UnicodeReplacer().replace(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation symbols: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "##removing panctuation\n",
    "import string\n",
    "punct = string.punctuation\n",
    "print(f\"Punctuation symbols: {punct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text, keep=[]):\n",
    "    punctuation = string.punctuation\n",
    "    for p in keep:\n",
    "        punctuation = punctuation.replace(p, \"\")\n",
    "    return(''.join([char if not char in punctuation else ' ' for char in text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean'] = posts['text_clean'].dropna().apply(lambda text: remove_punctuation(text, keep=\"#\")).apply(lambda text: remove_spaces(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Se i musulmani pensano di portare la guerra sa...</td>\n",
       "      <td>se i musulmani pensano di portare la guerra sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un mio particolare ringraziamento va ai Magist...</td>\n",
       "      <td>un mio particolare ringraziamento va ai magist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>🔴Quasi il 60% degli italiani è favorevole alla...</td>\n",
       "      <td>quasi il degli italiani è favorevole alla cast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>Il mio intervento ieri sera nella trasmissione...</td>\n",
       "      <td>il mio intervento ieri sera nella trasmissione...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10103 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Se i musulmani pensano di portare la guerra sa...   \n",
       "1      Un mio particolare ringraziamento va ai Magist...   \n",
       "...                                                  ...   \n",
       "10101  🔴Quasi il 60% degli italiani è favorevole alla...   \n",
       "10102  Il mio intervento ieri sera nella trasmissione...   \n",
       "\n",
       "                                              text_clean  \n",
       "0      se i musulmani pensano di portare la guerra sa...  \n",
       "1      un mio particolare ringraziamento va ai magist...  \n",
       "...                                                  ...  \n",
       "10101  quasi il degli italiani è favorevole alla cast...  \n",
       "10102  il mio intervento ieri sera nella trasmissione...  \n",
       "\n",
       "[10103 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.it.stop_words import STOP_WORDS as it_spacy_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/lynxy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "it_nltk_stopwords = nltk.corpus.stopwords.words('italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_stop_words=[\n",
    "     'a',\n",
    "     'adesso',\n",
    "     'ai',\n",
    "     'al',\n",
    "     'alla',\n",
    "     'allo',\n",
    "     'allora',\n",
    "     'almeno',\n",
    "     'altra',\n",
    "     'altre',\n",
    "     'altri',\n",
    "     'altro',\n",
    "     'anche',\n",
    "     'ancora',\n",
    "    'anno',\n",
    "     'appena',\n",
    "     'appieno',\n",
    "     'avanti',\n",
    "     'aver',\n",
    "     'avere',\n",
    "     'aveva',\n",
    "     'avevano',\n",
    "     'basta',\n",
    "     'bastare',\n",
    "     'bisogna',\n",
    "     'bisognare',\n",
    "     'bo',\n",
    "     'boh',\n",
    "     'capire',\n",
    "     'capisco',\n",
    "     'capite',\n",
    "     'capito',\n",
    "     'c',\n",
    "     \"c'\",\n",
    "     'ce',\n",
    "     'certo',\n",
    "     'che',\n",
    "     'chi',\n",
    "     'cio',\n",
    "     'ciò',\n",
    "     'cm',\n",
    "     'cmq',\n",
    "     'cn',\n",
    "     'come',\n",
    "     'comunque',\n",
    "     'con',\n",
    "     'cosa',\n",
    "     'cose',\n",
    "     'cosi',\n",
    "     'così',\n",
    "     'credo',\n",
    "     'cs',\n",
    "     'cui',\n",
    "     'd',\n",
    "     \"d'\",\n",
    "     'da',\n",
    "     'dà',\n",
    "     'dá',\n",
    "     'dapprima',\n",
    "     'data',\n",
    "     'date',\n",
    "     'dato',\n",
    "     'davvero',\n",
    "     'de',\n",
    "     'del',\n",
    "     'dell',\n",
    "     'della',\n",
    "     'dello',\n",
    "     'dentro',\n",
    "     'detto',\n",
    "     'deve',\n",
    "     'devo',\n",
    "     'devono',\n",
    "     'di',\n",
    "     'diciamo',\n",
    "     'dico',\n",
    "     'dicono',\n",
    "     'dite',\n",
    "     'dobbiamo',\n",
    "     'dovere',\n",
    "     'dovete',\n",
    "     'dovrebbe',\n",
    "     'dovrebbero',\n",
    "     'dovresti',\n",
    "     'doppio',\n",
    "     'due',\n",
    "     'e',\n",
    "     'è',\n",
    "     'ecco',\n",
    "     'eccoli',\n",
    "     'eccolo',\n",
    "     'er',\n",
    "     'essere',\n",
    "     'fare',\n",
    "     'finalmente',\n",
    "     'finche',\n",
    "     'finchè',\n",
    "     'fino',\n",
    "     'forse',\n",
    "     'fra',\n",
    "     'giu',\n",
    "     'giusto',\n",
    "     'guarda',\n",
    "     'ha',\n",
    "     'hai',\n",
    "     'hanno',\n",
    "     'ho',\n",
    "     'i',\n",
    "     'il',\n",
    "     'immediatamente',\n",
    "     'infatti',\n",
    "     'invece',\n",
    "     'io',\n",
    "     'k',\n",
    "     'ke',\n",
    "     'l',\n",
    "     \"l'\",\n",
    "     'la',\n",
    "     'le',\n",
    "     'lei',\n",
    "     'letto',\n",
    "     'lo',\n",
    "     'loro',\n",
    "     'lui',\n",
    "     'lungo',\n",
    "     'ma',\n",
    "     'magari',\n",
    "     'man',\n",
    "     'mano',\n",
    "     'me',\n",
    "     'meglio',\n",
    "     'mentre',\n",
    "     'mo',\n",
    "     'modo',\n",
    "     'molta',\n",
    "     'molti',\n",
    "     'molto',\n",
    "     'neanche',\n",
    "     'nei',\n",
    "     'nella',\n",
    "     'nemmeno',\n",
    "     'no',\n",
    "     'noi',\n",
    "     'nome',\n",
    "     'non',\n",
    "     'nn',\n",
    "     'nostro',\n",
    "     'notte',\n",
    "     'nove',\n",
    "     'nulla',\n",
    "     'nuova',\n",
    "     'nuove',\n",
    "     'nuovi',\n",
    "     'nuovo',\n",
    "     'o',\n",
    "     'oggi',\n",
    "     'ogni',\n",
    "     'ok',\n",
    "     'okay',\n",
    "     'okey',\n",
    "     'oltre',\n",
    "     'ora',\n",
    "     'oramai',\n",
    "     'ormai',\n",
    "     'otto',\n",
    "     'pare',\n",
    "     'pensa',\n",
    "     'pensi',\n",
    "     'penso',\n",
    "     'perche',\n",
    "     'perchè',\n",
    "     'perché',\n",
    "     'pero',\n",
    "     'però',\n",
    "     'peró',\n",
    "     'piu',\n",
    "     'più',\n",
    "     'piú',\n",
    "     'poco',\n",
    "     'possiamo',\n",
    "     'possibile',\n",
    "     'posso',\n",
    "     'possono',\n",
    "     'posto',\n",
    "     'prescindere',\n",
    "     'prima',\n",
    "     'primo',\n",
    "     'proprio',\n",
    "     'ps',\n",
    "     'puoi',\n",
    "     'purtroppo',\n",
    "     'qua',\n",
    "     'qualche',\n",
    "     'qualcosa',\n",
    "     'qualcuno',\n",
    "    'qualunque',\n",
    "    'qualsiasi',\n",
    "     'quarto',\n",
    "     'quasi',\n",
    "     'quattro',\n",
    "     'quel',\n",
    "     'quello',\n",
    "     'quest',\n",
    "     'questa',\n",
    "     'queste',\n",
    "     'questi',\n",
    "     'questo',\n",
    "     'qua',\n",
    "    'quando',\n",
    "     'qui',\n",
    "     'quindi',\n",
    "     'quinto',\n",
    "     'sa',\n",
    "     'sara',\n",
    "     'scusa',\n",
    "     'scusate',\n",
    "     'secondo',\n",
    "     'sei',\n",
    "     'sembra',\n",
    "     'sembrava',\n",
    "    'sempre',\n",
    "     'senso',\n",
    "     'senza',\n",
    "     'sette',\n",
    "     'sia',\n",
    "     'siamo',\n",
    "     'siete',\n",
    "     'solo',\n",
    "     'sono',\n",
    "     'sopra',\n",
    "     'soprattutto',\n",
    "     'sotto',\n",
    "     'speriamo',\n",
    "     'spero',\n",
    "     'stanotte',\n",
    "     'stasera',\n",
    "     'stati',\n",
    "     'stata',\n",
    "     'stato',\n",
    "     'stessa',\n",
    "     'stesso',\n",
    "     'sta',\n",
    "     'ste',\n",
    "     'sti',\n",
    "     'sto',\n",
    "     'su',\n",
    "     'subito',\n",
    "     'sul',\n",
    "     'sulla',\n",
    "     'tanta',\n",
    "     'tante',\n",
    "     'tanti',\n",
    "     'tanto',\n",
    "     'te',\n",
    "     'terzo',\n",
    "     'tipa',\n",
    "     'tipe',\n",
    "     'tipi',\n",
    "     'tipo',\n",
    "     'tra',\n",
    "     'tramite',\n",
    "     'tre',\n",
    "     'triplo',\n",
    "     'troppa',\n",
    "     'troppe',\n",
    "     'troppi',\n",
    "     'troppo',\n",
    "     'tutta',\n",
    "     'tutte',\n",
    "     'tutti',\n",
    "     'tutto',\n",
    "     'u',\n",
    "     'ultima',\n",
    "     'ultimo',\n",
    "     'un',\n",
    "     'una',\n",
    "     'uno',\n",
    "     'va',\n",
    "     'vabbe',\n",
    "     'vabbè',\n",
    "     'vai',\n",
    "     'vanno',\n",
    "     'vedere',\n",
    "     'vedo',\n",
    "     'vengo',\n",
    "     'venire',\n",
    "     'venuta',\n",
    "     'venute',\n",
    "     'venuti',\n",
    "     'venuto',\n",
    "     'vera',\n",
    "     'veramente',\n",
    "     'vere',\n",
    "     'veri',\n",
    "     'vero',\n",
    "     'verso',\n",
    "     'viene',\n",
    "     'vista',\n",
    "     'viste',\n",
    "     'visti',\n",
    "     'visto',\n",
    "     'voi',\n",
    "     'vogliamo',\n",
    "     'voglio',\n",
    "     'vogliono',\n",
    "     'volta',\n",
    "     'volte',\n",
    "     'vorrei',\n",
    "     'vorreste',\n",
    "     'vorresti',\n",
    "     'vorrebbero',\n",
    "     'vostro',\n",
    "     'vuoi',\n",
    "     'vuol',\n",
    "     'vuole',\n",
    "     'x',\n",
    "     'xche',\n",
    "     'xché',\n",
    "     'xk',\n",
    "     'xke',\n",
    "     'xké']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_stop=set(it_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "allstop=set(it_nltk_stopwords)|set_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(text):\n",
    "    return(' '.join([word for word in text.split() if word not in allstop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_upbra(text):\n",
    "    return re.sub('“',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tilde(text):\n",
    "    return re.sub('’',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean']=posts['text_clean'].dropna().apply(lambda text: remove_stop(text))\n",
    "posts['text_clean']=posts['text_clean'].dropna().apply(lambda text: replace_upbra(text))\n",
    "posts['text_clean']=posts['text_clean'].dropna().apply(lambda text: replace_tilde(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean'] = posts['text_clean'].dropna().apply(lambda text: remove_punctuation(text, keep=\"#\")).apply(lambda text: remove_spaces(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean']=posts['text_clean'].dropna().apply(lambda text: remove_stop(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean'] = posts['text_clean'].dropna().apply(lambda text: remove_punctuation(text, keep=\"#\")).apply(lambda text: remove_spaces(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple vowels? multiple consonants?\n",
    "import re\n",
    "def remove_duplicated(text):\n",
    "    return re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean']=posts['text_clean'].dropna().apply(lambda text: remove_duplicated(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Remove not significant one-char, two-char, three-char\n",
    "##\n",
    "word3=[]\n",
    "for post in posts['text_clean']:\n",
    "    a=' '.join([word for word in str(post).split() if len(word)<2])\n",
    "    for word in a:\n",
    "        word3.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_word_set=set(word3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ones(text):\n",
    "    return(' '.join([word for word in text.split() if word not in one_word_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean']=posts['text_clean'].dropna().apply(lambda text: remove_ones(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CHECK '''\n",
    "word3=[]\n",
    "for post in posts['text_clean']:\n",
    "    a=' '.join([word for word in str(post).split() if len(word)<2])\n",
    "    for word in a:\n",
    "        word3.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word3## successfully removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2 char words\n",
    "word4=[]\n",
    "\n",
    "for post in posts['text_clean']:\n",
    "    a=[word for word in str(post).split() if len(word)==2]\n",
    "    if a:\n",
    "        if len(a)>1:\n",
    "            for word in a:\n",
    "                word4.append(word)\n",
    "        else:\n",
    "            b=''.join(a)\n",
    "            word4.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_words_set=set(word4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually select relevant acronyms?\n",
    "# to keep: pd, ok\n",
    "two_words_set=set(word4)\n",
    "two_words_set.remove('pd')\n",
    "#two_words_set.remove('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_two(text):\n",
    "    return(' '.join([word for word in text.split() if word not in two_words_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean']=posts['text_clean'].dropna().apply(lambda text: remove_two(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''CHECK'''\n",
    "word4=[]\n",
    "\n",
    "for post in posts['text_clean']:\n",
    "    a=[word for word in str(post).split() if len(word)==2]\n",
    "    if a:\n",
    "        if len(a)>1:\n",
    "            for word in a:\n",
    "                word4.append(word)\n",
    "        else:\n",
    "            b=''.join(a)\n",
    "            word4.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "###remove the three letter words\n",
    "word5=[]\n",
    "\n",
    "for post in posts['text_clean']:\n",
    "    a=[word for word in str(post).split() if len(word)==3]\n",
    "    if a:\n",
    "        if len(a)>1:\n",
    "            for word in a:\n",
    "                word5.append(word)\n",
    "        else:\n",
    "            b=''.join(a)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_words_set=set(word5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_words_set.remove('gap')\n",
    "three_words_set.remove('mld')\n",
    "three_words_set.remove('ogm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_three(text):\n",
    "    return(' '.join([word for word in text.split() if word not in three_words_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean']=posts['text_clean'].dropna().apply(lambda text: remove_three(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LONG WORDS\n",
    "# spaces and puctuation double check\n",
    "posts['text_clean'] = posts['text_clean'].dropna().apply(lambda text: remove_punctuation(text, keep=\"#\")).apply(lambda text: remove_spaces(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Se i musulmani pensano di portare la guerra sa...</td>\n",
       "      <td>musulmani pensano portare guerra santa casa ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un mio particolare ringraziamento va ai Magist...</td>\n",
       "      <td>particolare ringraziamento magistrati palermit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>🔴Quasi il 60% degli italiani è favorevole alla...</td>\n",
       "      <td>italiani favorevole castrazione chimica pedofi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>Il mio intervento ieri sera nella trasmissione...</td>\n",
       "      <td>intervento ieri sera trasmissione dritto roves...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10103 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Se i musulmani pensano di portare la guerra sa...   \n",
       "1      Un mio particolare ringraziamento va ai Magist...   \n",
       "...                                                  ...   \n",
       "10101  🔴Quasi il 60% degli italiani è favorevole alla...   \n",
       "10102  Il mio intervento ieri sera nella trasmissione...   \n",
       "\n",
       "                                              text_clean  \n",
       "0      musulmani pensano portare guerra santa casa ar...  \n",
       "1      particolare ringraziamento magistrati palermit...  \n",
       "...                                                  ...  \n",
       "10101  italiani favorevole castrazione chimica pedofi...  \n",
       "10102  intervento ieri sera trasmissione dritto roves...  \n",
       "\n",
       "[10103 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 7891\n",
      "🇪🇺 Il mio intervento di ieri al #Sconcerto del primo maggio a Jesolo 👇🏻\n",
      "\n",
      "#europpe2019 #scriviGardini\n",
      "\n",
      "Fratelli d'Italia Giorgia Meloni\n",
      "intervento ieri #sconcerto maggio jesolo #europpe2019 #scrivigardini fratelli italia giorgia meloni \n",
      "\n",
      "\n",
      "Post 4373\n",
      "@Utente_Generico @CarloCalenda Certo, e col M5S.\n",
      " \n",
      "\n",
      "\n",
      "Post 5874\n",
      "#IoVotoDinoGiarrusso #IoVotoM5S #Europee2019\n",
      "#iovotodinogiarrusso #iovotom5s #europee2019 \n",
      "\n",
      "\n",
      "Post 6744\n",
      "Oggi alla Sapienza profumo di riscatto e libertà. L'odio non può governare l'Italia e verrà sconfitto\n",
      "sapienza profumo riscatto liberta odio governare italia verra sconfitto \n",
      "\n",
      "\n",
      "Post 3468\n",
      "Se il problema fosse di opportunità economica il Presidente della Rai ne discuterebbe negli organi aziendali con la dovuta riservatezza. Il problema è evidentemente politico. https://t.co/3oTjzRa0Dj\n",
      "problema opportunita economica presidente discuterebbe organi aziendali dovuta riservatezza problema evidentemente politico \n",
      "\n",
      "\n",
      "Post 705\n",
      "La cronaca e il video del mio sopralluogo nel quartiere fantasma di Milano dove, con il silenzio connivente della sinistra, rom e immigrati hanno occupato alcuni palazzi abbandonati e pretendono di dettare le regole in nome dell'illegalità. La sinistra li difende, io penso invece che a tutela dei cittadini siano azioni da condannare e risolvere!\n",
      "🔵Alle #europee #votaLEGA e #scriviSARDONE🔵\n",
      "cronaca video sopralluogo quartiere fantasma milano silenzio connivente sinistra immigrati occupato alcuni palazzi abbandonati pretendono dettare regole illegalita sinistra difende tutela cittadini azioni condannare risolvere #europee #votalega #scrivisardone \n",
      "\n",
      "\n",
      "Post 2599\n",
      "@Utente_Generico @forza_italia @GruppoFICamera @GruppoFISenato @Utente_Generico Io sono una di quelle persone che ha dato fiducia al Governo, ma ora mi sembra che su troppi temi sia immobile\n",
      "persone fiducia governo temi immobile \n",
      "\n",
      "\n",
      "Post 2222\n",
      "I Cinquestelle hanno imposto tutte le loro ricette economiche. Hanno varato, e intendono varare, molti provvedimenti pericolosi per la nostra libertà e i diritti dei cittadini. Salvini non può continuare su questa strada: sarebbe considerato corresponsabile, anche dai suoi, di tutto il male che questo governo sta facendo all'Italia e agli italiani. \n",
      "\n",
      "Ne ho parlato nella mia intervista a La Stampa.\n",
      "cinquestelle imposto ricette economiche varato intendono varare provvedimenti pericolosi liberta diritti cittadini salvini continuare strada considerato corresponsabile male governo italia italiani parlato intervista stampa \n",
      "\n",
      "\n",
      "Post 7768\n",
      "Ora in diretta a Matrix con Nicola Porro. Seguite l'intervista!\n",
      "diretta matrix nicola porro seguite intervista \n",
      "\n",
      "\n",
      "Post 2897\n",
      "Solito teatrino fra Salvini e Di Maio. Vogliamo scommettere che alla fine la Lega voterà il Salva Roma e in cambio il M5S tacerà su Siri?\n",
      "solito teatrino salvini maio scommettere fine lega votera salva roma cambio tacera siri \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in list(np.random.choice(list(posts.index), 10)):\n",
    "    print(f'Post {i}')\n",
    "    print(posts.loc[i]['text'])\n",
    "    print(posts.loc[i]['text_clean'], '\\n')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(text):\n",
    "    return [char for char in str(text) if char not in 'abcdefghijklmnopqrstuwvzxy# ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Se i musulmani pensano di portare la guerra sa...</td>\n",
       "      <td>musulmani pensano portare guerra santa casa ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un mio particolare ringraziamento va ai Magist...</td>\n",
       "      <td>particolare ringraziamento magistrati palermit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>🔴Quasi il 60% degli italiani è favorevole alla...</td>\n",
       "      <td>italiani favorevole castrazione chimica pedofi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>Il mio intervento ieri sera nella trasmissione...</td>\n",
       "      <td>intervento ieri sera trasmissione dritto roves...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Se i musulmani pensano di portare la guerra sa...   \n",
       "1      Un mio particolare ringraziamento va ai Magist...   \n",
       "...                                                  ...   \n",
       "10101  🔴Quasi il 60% degli italiani è favorevole alla...   \n",
       "10102  Il mio intervento ieri sera nella trasmissione...   \n",
       "\n",
       "                                              text_clean  \n",
       "0      musulmani pensano portare guerra santa casa ar...  \n",
       "1      particolare ringraziamento magistrati palermit...  \n",
       "...                                                  ...  \n",
       "10101  italiani favorevole castrazione chimica pedofi...  \n",
       "10102  intervento ieri sera trasmissione dritto roves...  \n",
       "\n",
       "[10102 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_char=[]\n",
    "for i in posts['text_clean'].index:\n",
    "    a = sanity_check(posts['text_clean'][i])\n",
    "    if a:\n",
    "        if len(a)>1:\n",
    "            for char in a:\n",
    "                spec_char.append(char)\n",
    "        else:\n",
    "            b=''.join(a)\n",
    "            spec_char.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_replace(dicti, text):\n",
    "  # Create a regular expression  from the dictionary keys\n",
    "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dicti.keys())))\n",
    "\n",
    "  # For each match, look-up corresponding value in dictionary\n",
    "  return regex.sub(lambda mo: dicti[mo.string[mo.start():mo.end()]], text) \n",
    "\n",
    "dicti = {\n",
    "    'à': \"a\",\n",
    "    'á' : \"a\",\n",
    "    'â' : \"a\",\n",
    "    'è' : 'e',\n",
    "    'é' :'e',\n",
    "    'ê' :'e',\n",
    "    'ì' :'i',\n",
    "    'í' :'i',\n",
    "    'î' :'i',\n",
    "    'ï' :'i',\n",
    "    'ò' : 'o',\n",
    "    'ó' : 'o',\n",
    "    'ô' :'o',\n",
    "    'ö' : 'o',\n",
    "    'ø' : 'o',\n",
    "    'ù' :'u',\n",
    "    'ú' :'u',\n",
    "    'ü' : 'u',\n",
    "    'ď' : 'd',\n",
    "    'ģ' : 'g',\n",
    "    'ĺ' : 'l',\n",
    "    'ľ' : 'l',\n",
    "    'ł' : 'l',\n",
    "    'ť' : 't',\n",
    "    'ź' : 'z',\n",
    "    '𝐀' : 'a',\n",
    "    '𝐈' : 'i',\n",
    "    '𝐏' : 'p',\n",
    "    '𝐑' : 'r',\n",
    "    '𝐕' : 'v',\n",
    "    '𝐚' : 'a',\n",
    "    '𝐜' : 'c',\n",
    "    '𝐝' : 'd',\n",
    "    '𝐞' : 'e',\n",
    "    '𝐡' : 'h',\n",
    "    '𝐢' : 'i',\n",
    "    '𝐦' : 'm',\n",
    "    '𝐧' : 'n',\n",
    "    '𝐨' : 'o',\n",
    "    '𝐩' : 'p',\n",
    "    '𝐫' : 'r',\n",
    "    '𝐬' : 's',\n",
    "    '𝐭' : 't',\n",
    "    '𝗔':'a',\n",
    "     '𝗕': 'b',\n",
    "     '𝗖': 'c',\n",
    "     '𝗗': 'd',\n",
    "     '𝗘': 'e',\n",
    "     '𝗙': 'f',\n",
    "     '𝗚': 'g',\n",
    "     '𝗜': 'i',\n",
    "     '𝗠': 'm',\n",
    "     '𝗡': 'n',\n",
    "     '𝗢': 'o',\n",
    "     '𝗣': 'p',\n",
    "     '𝗤': 'q',\n",
    "     '𝗥': 'r',\n",
    "     '𝗦': 's',\n",
    "     '𝗧': 't',\n",
    "     '𝗨': 'u',\n",
    "     '𝗩': 'v',\n",
    "     '𝗭': 'z',\n",
    "     '𝙂': 'g',\n",
    "     '𝙖': 'a',\n",
    "     '𝙙': 'd',\n",
    "     '𝙞': 'i',\n",
    "     '𝙣': 'n',\n",
    "     '𝙤': 'o',\n",
    "     '𝙧': 'r',\n",
    "     '𝙨': 's'\n",
    "  } \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean']=posts['text_clean'].dropna().apply(lambda text: multiple_replace(dicti,text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_char=[]\n",
    "for i in posts['text_clean'].index:\n",
    "    a=sanity_check(posts['text_clean'][i])\n",
    "    if a:\n",
    "        if len(a)>1:\n",
    "            for char in a:\n",
    "                spec_char.append(char)\n",
    "        else:\n",
    "            b=''.join(a)\n",
    "            spec_char.append(b)\n",
    "set_spec_char=set(spec_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spec_char(text):\n",
    "    return(''.join([char for char in str(text) if char not in set_spec_char]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['text_clean']=posts['text_clean'].dropna().apply(lambda text: remove_spec_char(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CHECK FOR SPECIAL CHAR'''\n",
    "spec_char=[]\n",
    "for i in posts['text_clean'].index:\n",
    "    a=sanity_check(posts['text_clean'][i])\n",
    "    if a:\n",
    "        if len(a)>1:\n",
    "            for char in a:\n",
    "                spec_char.append(char)\n",
    "        else:\n",
    "            b=''.join(a)\n",
    "            spec_char.append(b)\n",
    "set_spec_char=set(spec_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(spec_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10044,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=posts[posts['text_clean']!='']['text_clean']\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('Posts_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/lynxy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import it_core_news_lg\n",
    "nlp = it_core_news_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import _get_regex_pattern\n",
    "\n",
    "# get default pattern for tokens that don't get split\n",
    "re_token_match = _get_regex_pattern(nlp.Defaults.token_match)\n",
    "# add your patterns (here: hashtags and in-word hyphens)\n",
    "re_token_match = f\"({re_token_match}|#\\w+|\\w+-\\w+)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "nlp.tokenizer.token_match = re.compile(re_token_match).match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.read_csv('Posts_cleaned.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>musulmani pensano portare guerra santa casa ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>particolare ringraziamento magistrati palermit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>italiani favorevole castrazione chimica pedofi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>intervento ieri sera trasmissione dritto roves...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10044 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_clean\n",
       "0      musulmani pensano portare guerra santa casa ar...\n",
       "1      particolare ringraziamento magistrati palermit...\n",
       "...                                                  ...\n",
       "10101  italiani favorevole castrazione chimica pedofi...\n",
       "10102  intervento ieri sera trasmissione dritto roves...\n",
       "\n",
       "[10044 rows x 1 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nlp = final[\"text_clean\"].dropna().apply(lambda text: nlp(text))\n",
    "final['text_nlp'] = text_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pd.Series(final['text_nlp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save all the tokens\n",
    "tokens.to_csv('posts_all_tokens.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token               \tLemma               \tPOS                 \tis-stop \tis-punct\n",
      "musulmani           \tmusulmano           \tNOUN                \t   0    \n",
      "pensano             \tpensare             \tAUX                 \t   0    \n",
      "portare             \tportare             \tAUX                 \t   0    \n",
      "guerra              \tguerra              \tNOUN                \t   0    \n",
      "santa               \tsanto               \tADJ                 \t   0    \n",
      "casa                \tcasa                \tNOUN                \t   0    \n",
      "arrivato            \tarrivare            \tVERB                \t   0    \n",
      "momento             \tmomento             \tNOUN                \t   0    \n",
      "prendere            \tprendere            \tAUX                 \t   0    \n",
      "provvedimenti       \tprovvedimento       \tNOUN                \t   0    \n",
      "drastici            \tdrastico            \tADJ                 \t   0    \n",
      "resta               \trestare             \tVERB                \t   0    \n",
      "bloccare            \tbloccare            \tAUX                 \t   0    \n",
      "immigrazione        \timmigrazione        \tNOUN                \t   0    \n",
      "islamica            \tislamico            \tADJ                 \t   0    \n",
      "chiariti            \tchiarire            \tVERB                \t   0    \n",
      "idee                \tidea                \tNOUN                \t   0    \n",
      "intendiamo          \tintendere           \tVERB                \t   0    \n",
      "difendere           \tdifendere           \tAUX                 \t   0    \n",
      "radici              \tradice              \tNOUN                \t   0    \n",
      "classiche           \tclassico            \tADJ                 \t   0    \n",
      "cristiane           \tcristiano           \tADJ                 \t   0    \n",
      "processo            \tprocessare          \tNOUN                \t   0    \n",
      "islamizzazione      \tislamizzazione      \tPROPN               \t   0    \n",
      "europa              \teuropa              \tPROPN               \t   0    \n",
      "ragione             \tragione             \tNOUN                \t   0    \n",
      "buonisti            \tbuonista            \tADJ                 \t   0    \n",
      "sultani             \tsultano             \tNOUN                \t   0    \n",
      "mezzo               \tmezzo               \tADJ                 \t   0    \n",
      "mondo               \tmondare             \tNOUN                \t   0    \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Token':<20}\\t{'Lemma':<20}\\t{'POS':<20}\\t{'is-stop':<8}\\t{'is-punct':<8}\")\n",
    "for token in final['text_nlp'].loc[0]:\n",
    "    print(f\"{token.text:<20}\\t{token.lemma_:<20}\\t{token.pos_:<20}\\t{token.is_punct:^8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.dropna(inplace=True) ###drop na values resulting from cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-93-9df99a8d9e95>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final['lemmas'][i]=l[1:]\n",
      "/Users/lynxy/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# cycle through the tokens to extract the lemmas\n",
    "\n",
    "# initialize an empty row for the lemma in the dataframe\n",
    "final['lemmas']=0\n",
    "for i in final.index:\n",
    "    l=''\n",
    "#     print(i)\n",
    "    for token in final['text_nlp'][i]:\n",
    "        l=l+' '+token.lemma_\n",
    "    final['lemmas'][i]=l[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "for i in final.index:\n",
    "#     print(type(i))\n",
    "    for token in final['text_nlp'][i]:\n",
    "        lemmas.append(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_final=pd.DataFrame(final['lemmas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_final.rename(columns={'lemmas':'text_nlp'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_nlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>musulmano pensare portare guerra santo casa ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>particolare ringraziamento magistrato palermit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>italiano favorevole castrazione chimico pedofi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>intervento ieri sera trasmissione dritto roves...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10043 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text_nlp\n",
       "0      musulmano pensare portare guerra santo casa ar...\n",
       "1      particolare ringraziamento magistrato palermit...\n",
       "...                                                  ...\n",
       "10101  italiano favorevole castrazione chimico pedofi...\n",
       "10102  intervento ieri sera trasmissione dritto roves...\n",
       "\n",
       "[10043 rows x 1 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all lemmas as id_lemmas\n",
    "lemmas_final.to_csv('id_lemmas_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         musulmano\n",
       "1           pensare\n",
       "            ...    \n",
       "191089         poco\n",
       "191090    accordare\n",
       "Length: 191091, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lemmas=pd.Series(lemmas)\n",
    "all_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all lemmas\n",
    "all_lemmas.to_csv('Posts_lemmas_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17582"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_lemmas.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_unique=pd.Series(all_lemmas.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all unique lemmas\n",
    "lemmas_unique.to_csv('Posts_lemmas_unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
